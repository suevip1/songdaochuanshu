---
layout: post
title: "åŸºäºŽ Habana Gaudi çš„ Transformers å…¥é—¨"
date: "2023-08-02T01:04:37.824Z"
---
åŸºäºŽ Habana Gaudi çš„ Transformers å…¥é—¨
=================================

å‡ å‘¨å‰ï¼Œæˆ‘ä»¬å¾ˆé«˜å…´åœ° [å®£å¸ƒ](https://huggingface.co/blog/zh/habana) [Habana Labs](https://habana.ai) å’Œ [Hugging Face](https://huggingface.co/) å°†å¼€å±•åŠ é€Ÿ transformer æ¨¡åž‹çš„è®­ç»ƒæ–¹é¢çš„åˆä½œã€‚

ä¸Žæœ€æ–°çš„åŸºäºŽ GPU çš„ Amazon Web Services (AWS) EC2 å®žä¾‹ç›¸æ¯”ï¼ŒHabana Gaudi åŠ é€Ÿå¡åœ¨è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡åž‹æ–¹é¢çš„æ€§ä»·æ¯”æé«˜äº† 40%ã€‚æˆ‘ä»¬éžå¸¸é«˜å…´å°†è¿™ç§æ€§ä»·æ¯”ä¼˜åŠ¿å¼•å…¥ Transformers ðŸš€ã€‚

æœ¬æ–‡ï¼Œæˆ‘å°†æ‰‹æŠŠæ‰‹å‘ä½ å±•ç¤ºå¦‚ä½•åœ¨ AWS ä¸Šå¿«é€Ÿè®¾ç½® Habana Gaudi å®žä¾‹ï¼Œå¹¶ç”¨å…¶å¾®è°ƒä¸€ä¸ªç”¨äºŽæ–‡æœ¬åˆ†ç±»çš„ BERT æ¨¡åž‹ã€‚ä¸Žå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘ä»¬æä¾›äº†æ‰€æœ‰ä»£ç ï¼Œä»¥ä¾¿ä½ å¯ä»¥åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­é‡ç”¨å®ƒä»¬ã€‚

æˆ‘ä»¬å¼€å§‹å§ï¼

åœ¨ AWS ä¸Šè®¾ç½® Habana Gaudi å®žä¾‹
-------------------------

ä½¿ç”¨ Habana Gaudi åŠ é€Ÿå¡çš„æœ€ç®€å•æ–¹æ³•æ˜¯å¯åŠ¨ä¸€ä¸ª AWS EC2 [DL1](https://aws.amazon.com/ec2/instance-types/dl1/) å®žä¾‹ã€‚è¯¥å®žä¾‹é…å¤‡ 8 å¼  Habana Gaudi åŠ é€Ÿå¡ï¼Œå€ŸåŠ© [Habana æ·±åº¦å­¦ä¹ é•œåƒ (Amazon Machine Imageï¼ŒAMI)](https://aws.amazon.com/marketplace/server/procurement?productId=9a75c51a-a4d1-4470-884f-6be27933fcc8) ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾æŠŠå®ƒç”¨èµ·æ¥ã€‚è¯¥ AMI é¢„è£…äº† [Habana SynapseAIÂ® SDK](https://developer.habana.ai/) ä»¥åŠè¿è¡Œ Gaudi åŠ é€Ÿçš„ Docker å®¹å™¨æ‰€éœ€çš„å·¥å…·ã€‚å¦‚æžœä½ æƒ³ä½¿ç”¨å…¶ä»– AMI æˆ–å®¹å™¨ï¼Œè¯·å‚é˜… [Habana æ–‡æ¡£](https://docs.habana.ai/en/latest/AWS_Quick_Starts/index.html) ä¸­çš„è¯´æ˜Žã€‚

æˆ‘é¦–å…ˆç™»é™† `us-east-1` åŒºåŸŸçš„ [EC2 æŽ§åˆ¶å°](https://console.aws.amazon.com/ec2sp/v2/)ï¼Œç„¶åŽå•å‡» **å¯åŠ¨å®žä¾‹** å¹¶ç»™å®žä¾‹èµ·ä¸ªåå­— (æˆ‘ç”¨çš„æ˜¯ â€œhabana-demo-julsimonâ€)ã€‚

ç„¶åŽï¼Œæˆ‘åœ¨ Amazon Marketplace ä¸­æœç´¢ Habana AMIã€‚

![](https://man-archives.oss-cn-hangzhou.aliyuncs.com/goofan/202308011619016.png)

è¿™é‡Œï¼Œæˆ‘é€‰æ‹©äº† Habana Deep Learning Base AMI (Ubuntu 20.04)ã€‚

![](https://man-archives.oss-cn-hangzhou.aliyuncs.com/goofan/202308011620403.png)

æŽ¥ç€ï¼Œæˆ‘é€‰æ‹©äº† _dl1.24xlarge_ å®žä¾‹ (å®žé™…ä¸Šè¿™æ˜¯å”¯ä¸€å¯é€‰çš„å®žä¾‹)ã€‚

![](https://man-archives.oss-cn-hangzhou.aliyuncs.com/goofan/202308011620200.png)

æŽ¥ç€æ˜¯é€‰æ‹© `ssh` å¯†é’¥å¯¹ã€‚å¦‚æžœä½ æ²¡æœ‰å¯†é’¥å¯¹ï¼Œå¯ä»¥å°±åœ°åˆ›å»ºä¸€ä¸ªã€‚

![](https://man-archives.oss-cn-hangzhou.aliyuncs.com/goofan/202308011620794.png)

ä¸‹ä¸€æ­¥ï¼Œè¦ç¡®ä¿è¯¥å®žä¾‹å…è®¸æŽ¥å— `ssh` ä¼ è¾“ã€‚ä¸ºç®€å•èµ·è§ï¼Œæˆ‘å¹¶æœªé™åˆ¶æºåœ°å€ï¼Œä½†ä½ ç»å¯¹åº”è¯¥åœ¨ä½ çš„å¸æˆ·ä¸­è®¾ç½®ä¸€ä¸‹ï¼Œä»¥é˜²æ­¢è¢«æ¶æ„æ”»å‡»ã€‚

![](https://man-archives.oss-cn-hangzhou.aliyuncs.com/goofan/202308011621404.png)

é»˜è®¤æƒ…å†µä¸‹ï¼Œè¯¥ AMI å°†å¯åŠ¨ä¸€ä¸ªå…·æœ‰ 8GB Amazon EBS å­˜å‚¨çš„å®žä¾‹ã€‚ä½†è¿™å¯¹æˆ‘æ¥è¯´å¯èƒ½ä¸å¤Ÿï¼Œå› æ­¤æˆ‘å°†å­˜å‚¨ç©ºé—´å¢žåŠ åˆ° 50GBã€‚

![](https://man-archives.oss-cn-hangzhou.aliyuncs.com/goofan/202308011621270.png)

æŽ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦ä¸ºè¯¥å®žä¾‹åˆ†é…ä¸€ä¸ª Amazon IAM è§’è‰²ã€‚åœ¨å®žé™…é¡¹ç›®ä¸­ï¼Œæ­¤è§’è‰²åº”å…·æœ‰è¿è¡Œè®­ç»ƒæ‰€éœ€çš„æœ€ä½Žæƒé™ç»„åˆï¼Œä¾‹å¦‚ä»Ž Amazon S3 å­˜å‚¨æ¡¶ä¸­è¯»å–æ•°æ®çš„æƒé™ã€‚ä½†åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬ä¸éœ€è¦è¿™ä¸ªè§’è‰²ï¼Œå› ä¸ºæ•°æ®é›†æ˜¯ä»Ž Hugging Face Hub ä¸Šä¸‹è½½çš„ã€‚å¦‚æžœæ‚¨ä¸ç†Ÿæ‚‰ IAMï¼Œå¼ºçƒˆå»ºè®®é˜…è¯»è¿™ä¸ª [å…¥é—¨](https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started.html) æ–‡æ¡£ã€‚

ç„¶åŽï¼Œæˆ‘è¦æ±‚ EC2 å°†æˆ‘çš„å®žä¾‹é…ç½®ä¸º [Spot å®žä¾‹](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html)ï¼Œè¿™å¯ä»¥å¸®æˆ‘é™ä½Žæ¯å°æ—¶ä½¿ç”¨æˆæœ¬ (éž Spot å®žä¾‹æ¯å°æ—¶è¦ 13.11 ç¾Žå…ƒ)ã€‚

![](https://man-archives.oss-cn-hangzhou.aliyuncs.com/goofan/202308011621824.png)

æœ€åŽï¼Œå¯åŠ¨å®žä¾‹ã€‚å‡ åˆ†é’ŸåŽï¼Œå®žä¾‹å·²å‡†å¤‡å°±ç»ªï¼Œæˆ‘å¯ä»¥ä½¿ç”¨ `ssh` è¿žä¸Šå®ƒäº†ã€‚Windows ç”¨æˆ·å¯ä»¥æŒ‰ç…§ [æ–‡æ¡£](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/putty.html) ä½¿ç”¨ _PuTTY_ æ¥è¿žæŽ¥ã€‚

    ssh -i ~/.ssh/julsimon-keypair.pem ubuntu@ec2-18-207-189-109.compute-1.amazonaws.com
    

åœ¨å®žä¾‹ä¸­ï¼Œæœ€åŽä¸€æ­¥æ˜¯æ‹‰å–ä¸€ä¸ª Habana PyTorch å®¹å™¨ï¼Œæˆ‘åŽé¢ä¼šç”¨ PyTorch æ¥å¾®è°ƒæ¨¡åž‹ã€‚ä½ å¯ä»¥åœ¨ Habana [æ–‡æ¡£](https://docs.habana.ai/en/latest/Installation_Guide/index.html) ä¸­æ‰¾åˆ°æœ‰å…³å…¶ä»–é¢„æž„å»ºå®¹å™¨ä»¥åŠå¦‚ä½•æž„å»ºè‡ªå·±çš„å®¹å™¨çš„ä¿¡æ¯ã€‚

    docker pull \
    vault.habana.ai/gaudi-docker/1.5.0/ubuntu20.04/habanalabs/pytorch-installer-1.11.0:1.5.0-610
    

å°† docker é•œåƒæ‹‰åˆ°å®žä¾‹åŽï¼Œæˆ‘å°±å¯ä»¥ç”¨äº¤äº’æ¨¡å¼è¿è¡Œå®ƒã€‚

    docker run -it \
    --runtime=habana \
    -e HABANA_VISIBLE_DEVICES=all \
    -e OMPI_MCA_btl_vader_single_copy_mechanism=none \
    --cap-add=sys_nice \
    --net=host \
    --ipc=host vault.habana.ai/gaudi-docker/1.5.0/ubuntu20.04/habanalabs/pytorch-installer-1.11.0:1.5.0-610
    

è‡³æ­¤ï¼Œæˆ‘å°±å‡†å¤‡å¥½å¯ä»¥å¾®è°ƒæ¨¡åž‹äº†ã€‚

åœ¨ Habana Gaudi ä¸Šå¾®è°ƒæ–‡æœ¬åˆ†ç±»æ¨¡åž‹
------------------------

é¦–å…ˆï¼Œåœ¨åˆšåˆšå¯åŠ¨çš„å®¹å™¨å†…æ‹‰å– [Optimum Habana](https://github.com/huggingface/optimum-habana) å­˜å‚¨åº“ã€‚

    git clone https://github.com/huggingface/optimum-habana.git
    

ç„¶åŽï¼Œä»Žæºä»£ç å®‰è£… Optimum Habana è½¯ä»¶åŒ…ã€‚

    cd optimum-habana
    pip install .
    

æŽ¥ç€ï¼Œåˆ‡åˆ°åŒ…å«æ–‡æœ¬åˆ†ç±»ç¤ºä¾‹çš„å­ç›®å½•å¹¶å®‰è£…æ‰€éœ€çš„ Python åŒ…ã€‚

    cd examples/text-classification
    pip install -r requirements.txt
    

çŽ°åœ¨å¯ä»¥å¯åŠ¨è®­ç»ƒäº†ï¼Œè®­ç»ƒè„šæœ¬é¦–å…ˆä»Ž Hugging Face Hub ä¸‹è½½ [bert-large-uncased-whole-word-masking](https://huggingface.co/bert-large-uncased-whole-word-masking) æ¨¡åž‹ï¼Œç„¶åŽåœ¨ [GLUE](https://gluebenchmark.com/) åŸºå‡†çš„ [MRPC](https://www.microsoft.com/en-us/download/details.aspx?id=52398) ä»»åŠ¡ä¸Šå¯¹å…¶è¿›è¡Œå¾®è°ƒã€‚

è¯·æ³¨æ„ï¼Œæˆ‘ç”¨äºŽè®­ç»ƒçš„ BERT é…ç½®æ˜¯ä»Ž Hugging Face Hub èŽ·å–çš„ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨è‡ªå·±çš„é…ç½®ã€‚æ­¤å¤–ï¼ŒGaudi1 è¿˜æ”¯æŒå…¶ä»–æµè¡Œçš„æ¨¡åž‹ï¼Œä½ å¯ä»¥åœ¨ [Habana çš„ç½‘é¡µä¸Š](https://huggingface.co/Habana) ä¸­æ‰¾åˆ°å®ƒä»¬çš„é…ç½®æ–‡ä»¶ã€‚

    python run_glue.py \
    --model_name_or_path bert-large-uncased-whole-word-masking \
    --gaudi_config_name Habana/bert-large-uncased-whole-word-masking \
    --task_name mrpc \
    --do_train \
    --do_eval \
    --per_device_train_batch_size 32 \
    --learning_rate 3e-5 \
    --num_train_epochs 3 \
    --max_seq_length 128 \
    --use_habana \
    --use_lazy_mode \
    --output_dir ./output/mrpc/
    

2 åˆ† 12 ç§’åŽï¼Œè®­ç»ƒå®Œæˆï¼Œå¹¶èŽ·å¾—äº† 0.9181 çš„ F1 åˆ†æ•°ï¼Œç›¸å½“ä¸é”™ã€‚ä½ è¿˜å¯ä»¥å¢žåŠ  epoch æ•°ï¼ŒF1 åˆ†æ•°è‚¯å®šä¼šéšä¹‹ç»§ç»­æé«˜ã€‚

    ***** train metrics *****
      epoch                    =        3.0
      train_loss               =      0.371
      train_runtime            = 0:02:12.85
      train_samples            =       3668
      train_samples_per_second =     82.824
      train_steps_per_second   =      2.597
    
    ***** eval metrics *****
      epoch                   =        3.0
      eval_accuracy           =     0.8505
      eval_combined_score     =     0.8736
      eval_f1                 =     0.8968
      eval_loss               =      0.385
      eval_runtime            = 0:00:06.45
      eval_samples            =        408
      eval_samples_per_second =     63.206
      eval_steps_per_second   =      7.901
    

æœ€åŽä¸€æ­¥ä½†ä¹Ÿæ˜¯ç›¸å½“é‡è¦çš„ä¸€æ­¥ï¼Œç”¨å®ŒåŽåˆ«å¿˜äº†ç»ˆæ­¢ EC2 å®žä¾‹ä»¥é¿å…ä¸å¿…è¦çš„è´¹ç”¨ã€‚æŸ¥çœ‹ EC2 æŽ§åˆ¶å°ä¸­çš„ [Saving Summary](https://console.aws.amazon.com/ec2sp/v2/home/spot)ï¼Œæˆ‘å‘çŽ°ç”±äºŽä½¿ç”¨ Spot å®žä¾‹ï¼Œæˆ‘èŠ‚çœäº† 70% çš„æˆæœ¬ï¼Œæ¯å°æ—¶æ”¯ä»˜çš„é’±ä»ŽåŽŸå…ˆçš„ 13.11 ç¾Žå…ƒé™åˆ°äº† 3.93 ç¾Žå…ƒã€‚

![](https://man-archives.oss-cn-hangzhou.aliyuncs.com/goofan/202308011618231.png)

å¦‚ä½ æ‰€è§ï¼ŒTransformersã€Habana Gaudi å’Œ AWS å®žä¾‹çš„ç»„åˆåŠŸèƒ½å¼ºå¤§ã€ç®€å•ä¸”ç»æµŽé«˜æ•ˆã€‚æ¬¢è¿Žå¤§å®¶å°è¯•ï¼Œå¦‚æžœæœ‰ä»»ä½•æƒ³æ³•ï¼Œæ¬¢è¿Žå¤§å®¶åœ¨ [Hugging Face è®ºå›](https://discuss.huggingface.co/) ä¸Šæå‡ºé—®é¢˜å’Œåé¦ˆã€‚

* * *

_å¦‚æžœä½ æƒ³äº†è§£æ›´å¤šæœ‰å…³åœ¨ Gaudi ä¸Šè®­ç»ƒ Hugging Face æ¨¡åž‹çš„ä¿¡æ¯ï¼Œè¯· [è”ç³» Habana](https://developer.habana.ai/accelerate-transformer-training-on-habana-gaudi-processors-with-hugging-face/)ã€‚_

* * *

> è‹±æ–‡åŽŸæ–‡: [https://hf.co/blog/getting-started-habana](https://hf.co/blog/getting-started-habana)
> 
> åŽŸæ–‡ä½œè€…: Julien Simon
> 
> è¯‘è€…: Matrix Yao (å§šä¼Ÿå³°)ï¼Œè‹±ç‰¹å°”æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆï¼Œå·¥ä½œæ–¹å‘ä¸º transformer-family æ¨¡åž‹åœ¨å„æ¨¡æ€æ•°æ®ä¸Šçš„åº”ç”¨åŠå¤§è§„æ¨¡æ¨¡åž‹çš„è®­ç»ƒæŽ¨ç†ã€‚
> 
> å®¡æ ¡/æŽ’ç‰ˆ: zhongdongy (é˜¿ä¸œ)