---
layout: post
title: "GroundingDINO（一种开集目标检测算法）服务化，根据文本生成检测框"
date: "2023-05-27T01:09:21.999Z"
---
GroundingDINO（一种开集目标检测算法）服务化，根据文本生成检测框
======================================

背景
==

最近发现一个叫[GroundingDINO](https://github.com/IDEA-Research/GroundingDINO)的开集目标检测算法，所谓开集目标检测就是能检测的目标类别不局限于训练的类别，这个算法可以通过输入文本的prompt然后输出对应的目标框。可以用来做预标注或者其他应用，比如我们要训练某个细分场景的算法时，我们找不到足够的已经标注的数据，就可以先用这个算法预打标, 与SAM结合，还能做根据text去分割出物体。  
GroundingDINO：[https://github.com/IDEA-Research/GroundingDINO](https://github.com/IDEA-Research/GroundingDINO)  
![](https://img2023.cnblogs.com/blog/675649/202305/675649-20230526180436007-251645741.png)

将GroundingDINO服务化
=================

为什么要服务化
-------

原始的项目是一个python脚本，不适合单人使用，而不是和团队一起使用。服务化之后，其他人可以通过http请求的方式来访问，而不需要每个人都搭建环境，也便于批量处理数据。

如何服务化
-----

最简单的是通过flask api把python脚本包装一层，这种方式实现简单，但扩展性不够，比如如果想要动态组batch，就需要自己写这部分逻辑。更好的方式是使用成熟的模型推理服务，[TorchServe](https://github.com/pytorch/serve)就是其中的一种，比较适合pytorch模型（其实其他格式比如onnx也可以），使用TorchServe，我们只用写好模型的预处理、推理和后处理逻辑，其他的比如实例扩展、动态batch、资源监控这些都不需要我们自己实现。我们有其他模型，也可以用同样的方式服务起来，而不需要为每个模型都写一个服务。因此本文选择TorchServe来作为模型的推理服务。

过程
--

克隆文末的项目后按顺序执行下面步骤：

### 1.下载模型

新建一个weights目录，并把下面的模型放入：

    wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth
    

新建一个bert-base-uncased 目录，下载bert模型：  
[https://huggingface.co/bert-base-uncased/tree/main](https://huggingface.co/bert-base-uncased/tree/main)

    config.json
    pytorch_model.bin
    tokenizer_config.json
    tokenizer.json
    vocab.txt
    

### 2.制作torchserve镜像

Dockerfile:

    FROM pytorch/pytorch:2.0.1-cuda11.7-cudnn8-devel
    ARG DEBIAN_FRONTEND=noninteractive
    
    #for Chinese User, uncomment this line
    # COPY sources.list /etc/apt/sources.list
    
    RUN apt update && \
         apt install openjdk-17-jdk -y
    
    RUN apt install git -y
    
    #install python packages
    COPY requirements.txt /root/
    RUN pip install -r /root/requirements.txt --no-cache -i https://repo.huaweicloud.com/repository/pypi/simple/
    

    docker build -t torchserve:groundingdino .
    

### 3.转换模型

    docker run --rm -it -v $(pwd):/data -w /data torchserve:groundingdino bash -c "torch-model-archiver --model-name groundingdino --version 1.0 --serialized-file weights/groundingdino_swint_ogc.pth --handler grounding_dino_handler.py --extra-files GroundingDINO_SwinT_OGC.py,bert-base-uncased/*"
    

执行完毕后，将得到一个groundingdino.mar文件。

### 4.开启服务

根据需要修改服务的配置

    docker run -d --name groundingdino -v $(pwd)/model_store:/model_store -p 8080:8080 -p 8081:8081 -p 8082:8082 torchserve:groundingdino bash -c "torchserve --start --foreground --model-store /model_store --models groundingdino=groundingdino.mar"
    

### 5.调用服务

    import requests
    import base64
    import time
    # URL for the web service
    url = "http://ip:8080/predictions/groundingdino"
    headers = {"Content-Type": "application/json"}
    
    # Input data
    with open("test.jpg", "rb") as f:
        image = f.read()
    
    data = {
            "image": base64.b64encode(image).decode("utf-8"), # base64 encoded image or BytesIO
            "caption": "steel pipe", # text prompt, split by "." for multiple phrases
            "box_threshold": 0.25, # threshold for object detection
            "caption_threshold": 0.25 # threshold for text similarity
            }
    
    # Make the request and display the response
    
    resp = requests.post(url=url, headers=headers, json=data)
    outputs = resp.json()
    '''
    the outputs will be like:
        {
            "boxes": [[0.0, 0.0, 1.0, 1.0]], # list of bounding boxes in xyxy format
            "scores": [0.9999998807907104], # list of object detection scores
            "phrases": ["steel pipe"] # list of text phrases
        }
    
    '''
    

完整项目：[GroundingDINO-Service](https://github.com/HaoLiuHust/GroundingDINO-Service)

本文来自博客园，作者：[haoliuhust](https://www.cnblogs.com/haoliuhust/)，转载请注明原文链接：[https://www.cnblogs.com/haoliuhust/p/17435504.html](https://www.cnblogs.com/haoliuhust/p/17435504.html)