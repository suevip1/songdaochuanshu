---
layout: post
title: "【爬虫实战】用python爬豆瓣电影《热烈》短评"
date: "2023-09-08T00:56:25.094Z"
---
【爬虫实战】用python爬豆瓣电影《热烈》短评
========================

马哥原创：用python爬《豆瓣电影》任意电影的短评

目录

*   [一、爬虫对象-豆瓣电影短评](#一爬虫对象-豆瓣电影短评)
*   [二、爬取结果](#二爬取结果)
*   [三、爬虫代码讲解](#三爬虫代码讲解)
*   [三、演示视频](#三演示视频)
*   [四、获取完整源码](#四获取完整源码)

一、爬虫对象-豆瓣电影短评
=============

您好！我是[@马哥python说](https://www.cnblogs.com/mashukui/)，一名10年程序猿。

今天分享一期爬虫案例，爬取的目标是：豆瓣上任意一部电影的短评（注意：是短评，不是影评！），以《热烈》这部电影为例：  
![爬取目标](https://img2023.cnblogs.com/blog/2864563/202309/2864563-20230906212543369-855100527.png)

爬取以上6个关键字段，含：

> 页码, 评论者昵称, 评论星级, 评论时间, 评论者IP属地, 有用数, 评论内容。

二、爬取结果
======

爬取结果截图：  
![部分数据](https://img2023.cnblogs.com/blog/2864563/202309/2864563-20230906212607262-799581049.png)

三、爬虫代码讲解
========

首先，导入需要用到的库：

    import requests
    from bs4 import BeautifulSoup
    import pandas as pd
    import os
    import random
    from time import sleep
    

定义一个请求头：

    # 请求头
    h1 = {
    	'Cookie': '换成自己的cookie',
    	'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    	'Accept-Encoding': 'gzip, deflate',
    	'Host': 'movie.douban.com',
    	'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.4 Safari/605.1.15',
    	'Accept-Language': 'zh-CN,zh-Hans;q=0.9',
    	'Referer': 'https://movie.douban.com/subject/35267224/?from=showing',
    	'Connection': 'keep-alive'
    }
    

定义请求地址：（规律是：第1页start是0，第2页start是20，第3页start是40，所以总结出：start=(page-1)\*20）

    # 请求地址
    url = 'https://movie.douban.com/subject/{}/comments?start={}&limit=20&status=P&sort=new_score'.format(v_movie_id, (page - 1) * 20)
    

用requests发送请求：

    # 发送请求
    response = requests.get(url, headers=h1, verify=False)
    

用BeautifulSoup解析页面数据：

    # 解析页面数据
    soup = BeautifulSoup(response.text, 'html.parser')
    

定义一些空列表，用于存放数据：

    user_name_list = []  # 评论者昵称
    star_list = []  # 评论星级
    time_list = []  # 评论时间
    ip_list = []  # 评论者ip属地
    vote_list = []  # 有用数
    content_list = []  # 评论内容
    

以"评论内容"字段为例：

    for review in reviews:
    	# 评论内容
    	content = review.find('span', {'class': 'short'}).text
    	content = content.replace(',', '，').replace(' ', '').replace('\n', '').replace('\t', '').replace('\r', '')
    	content_list.append(content)
    

把所有字段存放的列表数据组成Dataframe格式：

    df = pd.DataFrame(
    	{
    		'页码': page,
    		'评论者昵称': user_name_list,
    		'评论星级': star_list,
    		'评论时间': time_list,
    		'评论者IP属地': ip_list,
    		'有用数': vote_list,
    		'评论内容': content_list,
    	}
    )
    

进一步保存到csv文件里：

    # 保存到csv
    df.to_csv(result_file, mode='a+', header=header, index=False, encoding='utf_8_sig')
    print('文件保存成功：', result_file)
    

以上，核心逻辑讲解完毕。

代码中还含有：转换星级函数、自动翻页、文本清洗等功能，详见文末完整源码。

最后需要说明的是，豆瓣短评页面上最多只能看到30页，再往后翻页面一直显示载入中，所以该代码最多只能爬取30页短评。  
![最多30页](https://img2023.cnblogs.com/blog/2864563/202309/2864563-20230907081015522-259362455.png)

三、演示视频
======

演示视频：[【Python爬虫实战】爬取豆瓣电影短评，以《热烈》为例](https://www.bilibili.com/video/BV1gh4y1v7VH/)

四、获取完整源码
========

爱学习的小伙伴，本次分析过程的完整python源码及结果数据，我已打包好，并上传至我的微信公众号"老男孩的平凡之路"，后台回复"爬豆瓣短评"即可获取。

点此直达：[【爬虫实战】用python爬豆瓣电影《热烈》短评](https://mp.weixin.qq.com/s/Jwo7OHoEzYbSDKCSx1YTyw)

* * *

我是[@马哥python说](https://www.cnblogs.com/mashukui)，一名10年程序猿，持续分享python干货中！