---
layout: post
title: "ä½¿ç”¨ AutoGPTQ å’Œ transformers è®©å¤§è¯­è¨€æ¨¡åž‹æ›´è½»é‡åŒ–"
date: "2023-08-26T00:54:25.099Z"
---
ä½¿ç”¨ AutoGPTQ å’Œ transformers è®©å¤§è¯­è¨€æ¨¡åž‹æ›´è½»é‡åŒ–
=====================================

å¤§è¯­è¨€æ¨¡åž‹åœ¨ç†è§£å’Œç”Ÿæˆäººç±»æ°´å¹³çš„æ–‡å­—æ–¹é¢æ‰€å±•çŽ°å‡ºçš„éžå‡¡èƒ½åŠ›ï¼Œæ­£åœ¨è®¸å¤šé¢†åŸŸå¸¦æ¥åº”ç”¨ä¸Šçš„é©æ–°ã€‚ç„¶è€Œï¼Œåœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè®­ç»ƒå’Œéƒ¨ç½²å¤§è¯­è¨€æ¨¡åž‹çš„éœ€æ±‚ä¹Ÿå˜å¾—è¶Šæ¥è¶Šéš¾ä»¥æ»¡è¶³ã€‚

ðŸ¤— Hugging Face çš„æ ¸å¿ƒä½¿å‘½æ˜¯ _è®©ä¼˜ç§€çš„æœºå™¨å­¦ä¹ æ™®æƒ åŒ–_ ï¼Œè€Œè¿™æ­£åŒ…æ‹¬äº†å°½å¯èƒ½åœ°è®©æ‰€æœ‰äººéƒ½èƒ½å¤Ÿä½¿ç”¨ä¸Šå¤§æ¨¡åž‹ã€‚æœ¬ç€ [ä¸Ž bitsandbytes åˆä½œ](https://huggingface.co/blog/4bit-transformers-bitsandbytes) ä¸€æ ·çš„ç²¾ç¥žï¼Œæˆ‘ä»¬å°† [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ) ä»£ç åº“é›†æˆåˆ°äº† Transformers ä¸­ï¼Œè®©ç”¨æˆ·ä½¿ç”¨ GPTQ ç®—æ³• ([Frantar et al. 2023](https://arxiv.org/pdf/2210.17323.pdf)) åœ¨ 8 ä½ã€4 ä½ã€3 ä½ï¼Œç”šè‡³æ˜¯ 2 ä½ç²¾åº¦ä¸‹é‡åŒ–å’Œè¿è¡Œæ¨¡åž‹æˆä¸ºå¯èƒ½ã€‚å½“ä½¿ç”¨ int4 é‡åŒ–æ—¶ï¼Œç²¾åº¦çš„ä¸‹é™å¯ä»¥å¿½ç•¥ä¸è®¡ï¼ŒåŒæ—¶åœ¨å°æ‰¹é‡æŽ¨ç†ä¸Šä¿æŒç€ä¸Ž `fp16` åŸºçº¿ç›¸å½“çš„é€Ÿåº¦ã€‚ éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒGPTQ æ–¹æ³•ä¸Ž bitsandbytes æå‡ºçš„è®­ç»ƒåŽé‡åŒ–æ–¹æ³•æœ‰æ‰€ä¸åŒ: å®ƒéœ€è¦åœ¨é‡åŒ–é˜¶æ®µæä¾›ä¸€ä¸ªæ ¡å‡†æ•°æ®é›†ã€‚

æœ¬æ¬¡é›†æˆæ”¯æŒè‹±ä¼Ÿè¾¾ GPU å’ŒåŸºäºŽ RoCm çš„ AMD GPUã€‚

ç›®å½•
--

*   [ç›¸å…³èµ„æº](#%E7%9B%B8%E5%85%B3%E8%B5%84%E6%BA%90)
*   [**GPTQ è®ºæ–‡æ€»ç»“**](#--gptq-%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93--)
*   [AutoGPTQ ä»£ç åº“â€”â€”ä¸€ç«™å¼åœ°å°† GPTQ æ–¹æ³•åº”ç”¨äºŽå¤§è¯­è¨€æ¨¡åž‹](#autogptq-%E4%BB%A3%E7%A0%81%E5%BA%93%E2%80%94%E2%80%94%E4%B8%80%E7%AB%99%E5%BC%8F%E5%9C%B0%E5%B0%86-gptq-%E6%96%B9%E6%B3%95%E5%BA%94%E7%94%A8%E4%BA%8E%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B)
*   [ðŸ¤— Transformers å¯¹ GPTQ æ¨¡åž‹çš„æœ¬åœ°åŒ–æ”¯æŒ](#---transformers-%E5%AF%B9-gptq-%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9C%AC%E5%9C%B0%E5%8C%96%E6%94%AF%E6%8C%81)
*   [ä½¿ç”¨ **Optimum ä»£ç åº“** é‡åŒ–æ¨¡åž‹](#%E4%BD%BF%E7%94%A8---optimum-%E4%BB%A3%E7%A0%81%E5%BA%93---%E9%87%8F%E5%8C%96%E6%A8%A1%E5%9E%8B)
*   [é€šè¿‡ _**Text-Generation-Inference**_ ä½¿ç”¨ GPTQ æ¨¡åž‹](#%E9%80%9A%E8%BF%87----text-generation-inference----%E4%BD%BF%E7%94%A8-gptq-%E6%A8%A1%E5%9E%8B)
*   [**ä½¿ç”¨ PEFT å¾®è°ƒé‡åŒ–åŽçš„æ¨¡åž‹**](#--%E4%BD%BF%E7%94%A8-peft-%E5%BE%AE%E8%B0%83%E9%87%8F%E5%8C%96%E5%90%8E%E7%9A%84%E6%A8%A1%E5%9E%8B--)
*   [æ”¹è¿›ç©ºé—´](#%E6%94%B9%E8%BF%9B%E7%A9%BA%E9%97%B4)
    *   [å·²æ”¯æŒçš„æ¨¡åž‹](#%E5%B7%B2%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B)
*   [ç»“è®ºå’Œç»“è¯­](#%E7%BB%93%E8%AE%BA%E5%92%8C%E7%BB%93%E8%AF%AD)
*   [è‡´è°¢](#%E8%87%B4%E8%B0%A2)

ç›¸å…³èµ„æº
----

æœ¬æ–‡åŠç›¸å…³ç‰ˆæœ¬å‘å¸ƒæä¾›äº†ä¸€äº›èµ„æºæ¥å¸®åŠ©ç”¨æˆ·å¼€å¯ GPTQ é‡åŒ–çš„æ—…ç¨‹:

*   [åŽŸå§‹è®ºæ–‡](https://arxiv.org/pdf/2210.17323.pdf)
*   [è¿è¡ŒäºŽ Google Colab ç¬”è®°æœ¬ä¸Šçš„åŸºç¡€ç”¨ä¾‹](https://colab.research.google.com/drive/1_TIrmuKOFhuRRiTWN94iLKUFu6ZX4ceb?usp=sharing) â€”â€” è¯¥ç¬”è®°æœ¬ä¸Šçš„ç”¨ä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ GPTQ æ–¹æ³•é‡åŒ–ä½ çš„ transformers æ¨¡åž‹ã€å¦‚ä½•è¿›è¡Œé‡åŒ–æ¨¡åž‹çš„æŽ¨ç†ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨é‡åŒ–åŽçš„æ¨¡åž‹è¿›è¡Œå¾®è°ƒã€‚
*   Transformers ä¸­é›†æˆ GPTQ çš„ [è¯´æ˜Žæ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/main_classes/quantization)
*   Optimum ä¸­é›†æˆ GPTQ çš„ [è¯´æ˜Žæ–‡æ¡£](https://huggingface.co/docs/optimum/llm_quantization/usage_guides/quantization)
*   TheBloke [æ¨¡åž‹ä»“åº“](https://huggingface.co/TheBloke?sort_models=likes#models) ä¸­çš„ GPTQ æ¨¡åž‹ã€‚

**GPTQ è®ºæ–‡æ€»ç»“**
-------------

é€šå¸¸ï¼Œé‡åŒ–æ–¹æ³•å¯ä»¥åˆ†ä¸ºä»¥ä¸‹ä¸¤ç±»:

1.  è®­ç»ƒåŽé‡åŒ– (Post Training Quantization, PTQ): é€‚åº¦åœ°ä½¿ç”¨ä¸€äº›èµ„æºæ¥é‡åŒ–é¢„è®­ç»ƒå¥½çš„æ¨¡åž‹ï¼Œå¦‚ä¸€ä¸ªæ ¡å‡†æ•°æ®é›†å’Œå‡ å°æ—¶çš„ç®—åŠ›ã€‚
2.  é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ (Quantization Aware Training, QAT): åœ¨è®­ç»ƒæˆ–è¿›ä¸€æ­¥å¾®è°ƒä¹‹å‰æ‰§è¡Œé‡åŒ–ã€‚

GPTQ å±žäºŽè®­ç»ƒåŽé‡åŒ–ï¼Œè¿™å¯¹äºŽå¤§æ¨¡åž‹è€Œè¨€æ ¼å¤–æœ‰è¶£ä¸”æœ‰æ„ä¹‰ï¼Œå› ä¸ºå¯¹å…¶è¿›è¡Œå…¨å‚æ•°è®­ç»ƒä»¥åŠç”šè‡³ä»…ä»…æ˜¯å¾®è°ƒéƒ½ååˆ†æ˜‚è´µã€‚

å…·ä½“è€Œè¨€ï¼ŒGPTQ é‡‡ç”¨ int4/fp16 (W4A16) çš„æ··åˆé‡åŒ–æ–¹æ¡ˆï¼Œå…¶ä¸­æ¨¡åž‹æƒé‡è¢«é‡åŒ–ä¸º int4 æ•°å€¼ç±»åž‹ï¼Œè€Œæ¿€æ´»å€¼åˆ™ä¿ç•™åœ¨ float16ã€‚åœ¨æŽ¨ç†é˜¶æ®µï¼Œæ¨¡åž‹æƒé‡è¢«åŠ¨æ€åœ°åé‡åŒ–å›ž float16 å¹¶åœ¨è¯¥æ•°å€¼ç±»åž‹ä¸‹è¿›è¡Œå®žé™…çš„è¿ç®—ã€‚

è¯¥æ–¹æ¡ˆæœ‰ä»¥ä¸‹ä¸¤æ–¹é¢çš„ä¼˜ç‚¹:

*   int4 é‡åŒ–èƒ½å¤ŸèŠ‚çœæŽ¥è¿‘4å€çš„å†…å­˜ï¼Œè¿™æ˜¯å› ä¸ºåé‡åŒ–æ“ä½œå‘ç”Ÿåœ¨ç®—å­çš„è®¡ç®—å•å…ƒé™„è¿‘ï¼Œè€Œä¸æ˜¯åœ¨ GPU çš„å…¨å±€å†…å­˜ä¸­ã€‚
*   ç”±äºŽç”¨äºŽæƒé‡çš„ä½å®½è¾ƒä½Žï¼Œå› æ­¤å¯ä»¥èŠ‚çœæ•°æ®é€šä¿¡çš„æ—¶é—´ï¼Œä»Žè€Œæ½œåœ¨åœ°æå‡äº†æŽ¨ç†é€Ÿåº¦ã€‚

GPTQ è®ºæ–‡è§£å†³äº†åˆ†å±‚åŽ‹ç¼©çš„é—®é¢˜:

ç»™å®šä¸€ä¸ªæ‹¥æœ‰æƒé‡çŸ©é˜µ \\(W\_{l}\\) å’Œè¾“å…¥ \\(X\_{l}\\) çš„ç½‘ç»œå±‚ \\(l\\)ï¼Œæˆ‘ä»¬æœŸæœ›èŽ·å¾—ä¸€ä¸ªé‡åŒ–ç‰ˆæœ¬çš„æƒé‡çŸ©é˜µ \\(\\hat{W}\_{l}\\) ä»¥æœ€å°åŒ–å‡æ–¹è¯¯å·® (MSE):

\\\[{\\hat{W}\_{l}}^{\*} = argmin\_{\\hat{W\_{l}}} \\|W\_{l}X-\\hat{W}\_{l}X\\|^{2}\_{2} \\\]

ä¸€æ—¦æ¯å±‚éƒ½å®žçŽ°äº†ä¸Šè¿°ç›®æ ‡ï¼Œå°±å¯ä»¥é€šè¿‡ç»„åˆå„ç½‘ç»œå±‚é‡åŒ–ç»“æžœçš„æ–¹å¼æ¥èŽ·å¾—ä¸€ä¸ªå®Œæ•´çš„é‡åŒ–æ¨¡åž‹ã€‚

ä¸ºè§£å†³è¿™ä¸€åˆ†å±‚åŽ‹ç¼©é—®é¢˜ï¼Œè®ºæ–‡ä½œè€…é‡‡ç”¨äº†æœ€ä¼˜è„‘é‡åŒ– (Optimal Brain Quantization, OBQ) æ¡†æž¶ ([Frantar et al 2022](https://arxiv.org/abs/2208.11580)) ã€‚OBQ æ–¹æ³•çš„å‡ºå‘ç‚¹åœ¨äºŽå…¶è§‚å¯Ÿåˆ°: ä»¥ä¸Šç­‰å¼å¯ä»¥æ”¹å†™æˆæƒé‡çŸ©é˜µ \\(W\_{l}\\) æ¯ä¸€è¡Œçš„å¹³æ–¹è¯¯å·®ä¹‹å’Œ

\\\[\\sum\_{i=0}^{d\_{row}} \\|W\_{l\[i,:\]}X-\\hat{W}\_{l\[i,:\]}X\\|^{2}\_{2} \\\]

è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ç‹¬ç«‹åœ°å¯¹æ¯ä¸€è¡Œæ‰§è¡Œé‡åŒ–ã€‚å³æ‰€è°“çš„ per-channel quantizationã€‚å¯¹æ¯ä¸€è¡Œ \\(W\_{l\[i,:\]}\\)ï¼ŒOBQ åœ¨æ¯ä¸€æ—¶åˆ»åªé‡åŒ–ä¸€ä¸ªæƒé‡ï¼ŒåŒæ—¶æ›´æ–°æ‰€æœ‰æœªè¢«é‡åŒ–çš„æƒé‡ï¼Œä»¥è¡¥å¿é‡åŒ–å•ä¸ªæƒé‡æ‰€å¸¦æ¥çš„è¯¯å·®ã€‚æ‰€é€‰æƒé‡çš„æ›´æ–°é‡‡ç”¨ä¸€ä¸ªé—­çŽ¯å…¬å¼ï¼Œå¹¶åˆ©ç”¨äº†æµ·æ£®çŸ©é˜µ (Hessian Matrices)ã€‚

GPTQ è®ºæ–‡é€šè¿‡å¼•å…¥ä¸€ç³»åˆ—ä¼˜åŒ–æŽªæ–½æ¥æ”¹è¿›ä¸Šè¿°é‡åŒ–æ¡†æž¶ï¼Œåœ¨é™ä½Žé‡åŒ–ç®—æ³•å¤æ‚åº¦çš„åŒæ—¶ä¿ç•™äº†æ¨¡åž‹çš„ç²¾åº¦ã€‚

ç›¸è¾ƒäºŽ OBQï¼ŒGPTQ çš„é‡åŒ–æ­¥éª¤æœ¬èº«ä¹Ÿæ›´å¿«: OBQ éœ€è¦èŠ±è´¹ 2 ä¸ª GPU æ—¶æ¥å®Œæˆ BERT æ¨¡åž‹ (336M) çš„é‡åŒ–ï¼Œè€Œä½¿ç”¨ GPTQï¼Œé‡åŒ–ä¸€ä¸ª Bloom æ¨¡åž‹ (176B) åˆ™åªéœ€ä¸åˆ° 4 ä¸ª GPU æ—¶ã€‚

ä¸ºäº†è§£ç®—æ³•çš„æ›´å¤šç»†èŠ‚ä»¥åŠåœ¨å›°æƒ‘åº¦ (perplexity, PPL) æŒ‡æ ‡å’ŒæŽ¨ç†é€Ÿåº¦ä¸Šçš„ä¸åŒæµ‹è¯„æ•°æ®ï¼Œå¯æŸ¥é˜…åŽŸå§‹ [è®ºæ–‡](https://arxiv.org/pdf/2210.17323.pdf) ã€‚

AutoGPTQ ä»£ç åº“â€”â€”ä¸€ç«™å¼åœ°å°† GPTQ æ–¹æ³•åº”ç”¨äºŽå¤§è¯­è¨€æ¨¡åž‹
-----------------------------------

AutoGPTQ ä»£ç åº“è®©ç”¨æˆ·èƒ½å¤Ÿä½¿ç”¨ GPTQ æ–¹æ³•é‡åŒ– ðŸ¤— Transformers ä¸­æ”¯æŒçš„å¤§é‡æ¨¡åž‹ï¼Œè€Œç¤¾åŒºä¸­çš„å…¶ä»–å¹³è¡Œå·¥ä½œå¦‚ [GPTQ-for-LLaMa](https://github.com/qwopqwop200/GPTQ-for-LLaMa) ã€[Exllama](https://github.com/turboderp/exllama) å’Œ [llama.cpp](https://github.com/ggerganov/llama.cpp/) åˆ™ä¸»è¦é’ˆå¯¹ Llama æ¨¡åž‹æž¶æž„å®žçŽ°é‡åŒ–ç­–ç•¥ã€‚ç›¸è¾ƒä¹‹ä¸‹ï¼ŒAutoGPTQ å› å…¶å¯¹ä¸°å¯Œçš„ transformers æž¶æž„çš„å¹³æ»‘è¦†ç›–è€Œå¹¿å—æ¬¢è¿Žã€‚

æ­£å› ä¸º AutoGPTQ ä»£ç åº“è¦†ç›–äº†å¤§é‡çš„ transformers æ¨¡åž‹ï¼Œæˆ‘ä»¬å†³å®šæä¾›ä¸€ä¸ª ðŸ¤— Transformers çš„ API é›†æˆï¼Œè®©æ¯ä¸ªäººéƒ½èƒ½å¤Ÿæ›´å®¹æ˜“åœ°ä½¿ç”¨å¤§è¯­è¨€æ¨¡åž‹é‡åŒ–æŠ€æœ¯ã€‚æˆªæ­¢ç›®å‰ï¼Œæˆ‘ä»¬å·²ç»é›†æˆäº†åŒ…æ‹¬ CUDA ç®—å­åœ¨å†…çš„æœ€å¸¸ç”¨çš„ä¼˜åŒ–é€‰é¡¹ã€‚å¯¹äºŽæ›´å¤šé«˜çº§é€‰é¡¹å¦‚ä½¿ç”¨ Triton ç®—å­å’Œ (æˆ–) å…¼å®¹æ³¨æ„åŠ›çš„ç®—å­èžåˆï¼Œè¯·æŸ¥çœ‹ [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ) ä»£ç åº“ã€‚

ðŸ¤— Transformers å¯¹ GPTQ æ¨¡åž‹çš„æœ¬åœ°åŒ–æ”¯æŒ
-------------------------------

åœ¨ [å®‰è£… AutoGPTQ ä»£ç åº“](https://github.com/PanQiWei/AutoGPTQ#quick-installation) å’Œ `optimum` (`pip install optimum`) ä¹‹åŽï¼Œåœ¨ Transformers ä¸­è¿è¡Œ GPTQ æ¨¡åž‹å°†éžå¸¸ç®€å•:

    from transformers import AutoModelForCausalLM
    
    model = AutoModelForCausalLM.from_pretrained("TheBloke/Llama-2-7b-Chat-GPTQ", torch_dtype=torch.float16, device_map="auto")
    

è¯·æŸ¥é˜… Transformers çš„ [è¯´æ˜Žæ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/main_classes/quantization) ä»¥äº†è§£æœ‰å…³æ‰€æœ‰ç‰¹æ€§çš„æ›´å¤šä¿¡æ¯ã€‚

æˆ‘ä»¬çš„ AutoGPTQ é›†æˆæœ‰ä»¥ä¸‹è¯¸å¤šä¼˜ç‚¹:

*   é‡åŒ–æ¨¡åž‹å¯è¢«åºåˆ—åŒ–å¹¶åœ¨ Hugging Face Hub ä¸Šåˆ†äº«ã€‚
*   GPTQ æ–¹æ³•å¤§å¤§é™ä½Žè¿è¡Œå¤§è¯­è¨€æ¨¡åž‹æ‰€éœ€çš„å†…å­˜ï¼ŒåŒæ—¶ä¿æŒç€ä¸Ž FP16 ç›¸å½“çš„æŽ¨ç†é€Ÿåº¦ã€‚
*   AutoGPTQ åœ¨æ›´å¹¿æ³›çš„ transformers æž¶æž„ä¸Šæ”¯æŒ Exllama ç®—å­ã€‚
*   è¯¥é›†æˆå¸¦æœ‰åŸºäºŽ RoCm çš„ AMD GPU çš„æœ¬åœ°åŒ–æ”¯æŒã€‚
*   èƒ½å¤Ÿ [**ä½¿ç”¨ PEFT å¾®è°ƒé‡åŒ–åŽçš„æ¨¡åž‹**](#--%E4%BD%BF%E7%94%A8-peft-%E5%BE%AE%E8%B0%83%E9%87%8F%E5%8C%96%E5%90%8E%E7%9A%84%E6%A8%A1%E5%9E%8B--) ã€‚

ä½ å¯ä»¥åœ¨ Hugging Face Hub ä¸ŠæŸ¥çœ‹ä½ æ‰€å–œçˆ±çš„æ¨¡åž‹æ˜¯å¦å·²ç»æ‹¥æœ‰ GPTQ é‡åŒ–ç‰ˆæœ¬ã€‚TheBlokeï¼ŒHugging Face çš„é¡¶çº§è´¡çŒ®è€…ä¹‹ä¸€ï¼Œå·²ç»ä½¿ç”¨ AutoGPTQ é‡åŒ–äº†å¤§é‡çš„æ¨¡åž‹å¹¶åˆ†äº«åœ¨ Hugging Face Hub ä¸Šã€‚åœ¨æˆ‘ä»¬çš„å…±åŒåŠªåŠ›ä¸‹ï¼Œè¿™äº›æ¨¡åž‹ä»“åº“éƒ½å°†å¯ä»¥ä¸Žæˆ‘ä»¬çš„é›†æˆä¸€èµ·å¼€ç®±å³ç”¨ã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨ batch size = 1 çš„æµ‹è¯„ç»“æžœç¤ºä¾‹ã€‚è¯¥æµ‹è¯„ç»“æžœé€šè¿‡åœ¨è‹±ä¼Ÿè¾¾ A100-SXM4-80GB GPU ä¸Šè¿è¡Œå¾—åˆ°ã€‚æˆ‘ä»¬ä½¿ç”¨é•¿åº¦ä¸º 512 ä¸ªè¯å…ƒçš„æç¤ºæ–‡æœ¬ï¼Œå¹¶ç²¾ç¡®åœ°ç”Ÿæˆ 512 ä¸ªæ–°è¯å…ƒã€‚è¡¨æ ¼çš„ç¬¬ä¸€è¡Œå±•ç¤ºçš„æ˜¯æœªé‡åŒ–çš„ `fp16` åŸºçº¿ï¼Œå¦å¤–ä¸¤è¡Œåˆ™å±•ç¤ºä½¿ç”¨ AutoGPTQ ä¸åŒç®—å­çš„å†…å­˜å¼€é”€å’ŒæŽ¨ç†æ€§èƒ½ã€‚

gptq

act\_order

bits

group\_size

kernel

Load time (s)

Per-token latency (ms)

Throughput (tokens/s)

Peak memory (MB)

False

None

None

None

None

26.0

36.958

27.058

29152.98

True

False

4

128

exllama

36.2

33.711

29.663

10484.34

True

False

4

128

autogptq-cuda-old

36.2

46.44

21.53

10344.62

ä¸€ä¸ªæ›´å…¨é¢çš„ã€å¯å¤çŽ°çš„æµ‹è¯„ç»“æžœå¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/huggingface/optimum/tree/main/tests/benchmark#gptq-benchmark) å–å¾—ã€‚

ä½¿ç”¨ **Optimum ä»£ç åº“** é‡åŒ–æ¨¡åž‹
-----------------------

ä¸ºäº†å°† AutoGPTQ æ— ç¼é›†æˆåˆ° Transformers ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† AutoGPTQ API çš„ä¸€ä¸ªæžç®€ç‰ˆæœ¬ï¼Œå…¶å¯åœ¨ [Optimum](https://github.com/huggingface/optimum) ä¸­èŽ·å¾— â€”â€” è¿™æ˜¯ Hugging Face é’ˆå¯¹è®­ç»ƒå’ŒæŽ¨ç†ä¼˜åŒ–è€Œå¼€å‘çš„ä¸€ä¸ªå·¥å…·åŒ…ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬è½»æ¾åœ°å®žçŽ°äº†ä¸Ž Transformers çš„é›†æˆï¼ŒåŒæ—¶ï¼Œå¦‚æžœäººä»¬æƒ³è¦é‡åŒ–ä»–ä»¬è‡ªå·±çš„æ¨¡åž‹ï¼Œä»–ä»¬ä¹Ÿå®Œå…¨å¯ä»¥å•ç‹¬ä½¿ç”¨ Optimum çš„ APIï¼å¦‚æžœæƒ³è¦é‡åŒ–ä½ è‡ªå·±çš„å¤§è¯­è¨€æ¨¡åž‹ï¼Œè¯·æŸ¥é˜… Optimum çš„ [è¯´æ˜Žæ–‡æ¡£](https://huggingface.co/docs/optimum/llm_quantization/usage_guides/quantization) ã€‚

åªéœ€æ•°è¡Œä»£ç ï¼Œå³å¯ä½¿ç”¨ GPTQ æ–¹æ³•é‡åŒ– ðŸ¤— Transformers çš„æ¨¡åž‹:

    from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig
    
    model_id = "facebook/opt-125m"
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    quantization_config = GPTQConfig(bits=4, dataset = "c4", tokenizer=tokenizer)
    
    model = AutoModelForCausalLM.from_pretrained(model_id, device_map="auto", quantization_config=quantization_config)
    

é‡åŒ–ä¸€ä¸ªæ¨¡åž‹å¯èƒ½èŠ±è´¹è¾ƒé•¿çš„æ—¶é—´ã€‚å¯¹äºŽä¸€ä¸ª 175B å‚æ•°é‡çš„æ¨¡åž‹ï¼Œå¦‚æžœä½¿ç”¨ä¸€ä¸ªå¤§åž‹æ ¡å‡†æ•°æ®é›† (å¦‚ â€œc4â€)ï¼Œè‡³å°‘éœ€è¦ 4 ä¸ª GPU æ—¶ã€‚æ­£å¦‚ä¸Šé¢æåˆ°çš„é‚£æ ·ï¼Œè®¸å¤š GPTQ æ¨¡åž‹å·²ç»å¯ä»¥åœ¨ Hugging Face Hub ä¸Šè¢«å–å¾—ï¼Œè¿™è®©ä½ åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æ— éœ€è‡ªè¡Œé‡åŒ–æ¨¡åž‹ã€‚å½“ç„¶ï¼Œä½ ä»å¯ä»¥ä½¿ç”¨ä½ æ‰€ä¸“æ³¨çš„ç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†æ¥é‡åŒ–æ¨¡åž‹ã€‚

é€šè¿‡ _**Text-Generation-Inference**_ ä½¿ç”¨ GPTQ æ¨¡åž‹
---------------------------------------------

åœ¨å°† GPTQ é›†æˆåˆ° Transformers ä¸­çš„åŒæ—¶ï¼Œ[Text-Generation-Inference ä»£ç åº“](https://github.com/huggingface/text-generation-inference) (TGI) å·²ç»æ·»åŠ äº† GPTQ çš„æ”¯æŒï¼Œæ—¨åœ¨ä¸ºç”Ÿäº§ä¸­çš„å¤§è¯­è¨€æ¨¡åž‹æä¾›æœåŠ¡ã€‚çŽ°åœ¨ï¼ŒGPTQ å·²ç»å¯ä»¥ä¸ŽåŠ¨æ€æ‰¹å¤„ç†ã€paged attentionã€flash attention ç­‰ç‰¹æ€§ä¸€èµ·è¢«åº”ç”¨äºŽ [å¹¿æ³›çš„ transformers æ¨¡åž‹æž¶æž„](https://huggingface.co/docs/text-generation-inference/main/en/supported_models) ã€‚

ä¾‹å¦‚ï¼Œè¿™ä¸€é›†æˆå…è®¸åœ¨å•ä¸ª A100-80GB GPUä¸ŠæœåŠ¡ 70B æ¨¡åž‹ï¼è€Œè¿™åœ¨ä½¿ç”¨ fp16 çš„æ¨¡åž‹æƒé‡æ—¶æ˜¯ä¸å¯èƒ½çš„ï¼Œå› ä¸ºå®ƒè¶…å‡ºäº†æœ€å¤§å¯ç”¨çš„ GPU å†…å­˜ã€‚

ä½ å¯ä»¥åœ¨ TGI çš„ [è¯´æ˜Žæ–‡æ¡£](https://huggingface.co/docs/text-generation-inference/main/en/basic_tutorials/preparing_model#quantization) ä¸­æ‰¾åˆ°æ›´å¤šæœ‰å…³ GPTQ çš„ç”¨æ³•ã€‚

éœ€è¦æ³¨æ„çš„æ—¶ï¼ŒTGI ä¸­é›†æˆçš„ç®—å­ä¸èƒ½å¾ˆå¥½åœ°æ‰©å±•åˆ°è¾ƒå¤§çš„æ‰¹å¤„ç†å¤§å°ã€‚å› æ­¤ï¼Œè¿™ä¸€æ–¹å¼è™½ç„¶èŠ‚çœäº†å†…å­˜ï¼Œä½†åœ¨è¾ƒå¤§çš„æ‰¹å¤„ç†å¤§å°ä¸Šå‘ç”Ÿé€Ÿåº¦çš„ä¸‹é™æ˜¯ç¬¦åˆé¢„æœŸçš„ã€‚

**ä½¿ç”¨ PEFT å¾®è°ƒé‡åŒ–åŽçš„æ¨¡åž‹**
--------------------

åœ¨å¸¸è§„çš„æ–¹æ³•ä¸‹ï¼Œä½ æ— æ³•è¿›ä¸€æ­¥å¾®è°ƒé‡åŒ–åŽçš„æ¨¡åž‹ã€‚ç„¶è€Œï¼Œé€šè¿‡ä½¿ç”¨ PEFT ä»£ç åº“ï¼Œä½ å¯ä»¥åœ¨é‡åŒ–åŽçš„æ¨¡åž‹ä¹‹ä¸Šè®­ç»ƒé€‚åº”æ€§ç½‘ç»œï¼ä¸ºå®žçŽ°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬å†»ç»“äº†é‡åŒ–è¿‡çš„åŸºåº§æ¨¡åž‹çš„æ‰€æœ‰ç½‘ç»œå±‚ï¼Œå¹¶é¢å¤–æ·»åŠ å¯è®­ç»ƒçš„é€‚åº”æ€§ç½‘ç»œã€‚è¿™é‡Œæ˜¯ä¸€äº›å…³äºŽå¦‚ä½•ä½¿ç”¨ PEFT è®­ç»ƒ GPTQ æ¨¡åž‹çš„ä¾‹å­: [Colab ç¬”è®°æœ¬](https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing) å’Œ [å¾®è°ƒè„šæœ¬](https://gist.github.com/SunMarc/dcdb499ac16d355a8f265aa497645996) ã€‚

æ”¹è¿›ç©ºé—´
----

è™½ç„¶æˆ‘ä»¬çš„ AutoGPTQ é›†æˆåœ¨æžå°çš„é¢„æµ‹è´¨é‡æŸå¤±ä»£ä»·ä¸‹ï¼Œå¸¦æ¥äº†å¼•äººçž©ç›®çš„ä¼˜åŠ¿ã€‚ä½†åœ¨é‡åŒ–æŠ€æœ¯åº”ç”¨å’Œç®—å­å®žçŽ°æ–¹é¢ä»æœ‰æå‡çš„ç©ºé—´ã€‚

é¦–å…ˆï¼Œå°½ç®¡ AutoGPTQ (åœ¨æˆ‘ä»¬çš„è®¤çŸ¥èŒƒå›´å†…) å·²ç»é›†æˆäº† [exllama](https://github.com/turboderp/exllama) ä¸­æ‰€å®žçŽ°çš„æœ€ä½³æ€§èƒ½çš„ W4A16 ç®—å­ (æƒé‡ä¸º int4 æ•°å€¼ç±»åž‹ï¼Œæ¿€æ´»å€¼ä¸º fp16 æ•°å€¼ç±»åž‹)ï¼Œå…¶ä»æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚æ¥è‡ª [Kim ç­‰äºº](https://arxiv.org/pdf/2211.10017.pdf) çš„å®žçŽ°å’Œ [MIT Han Lab](https://github.com/mit-han-lab/llm-awq) çš„æ–¹æ³•ä¼¼ä¹Žååˆ†å¯é ã€‚æ­¤å¤–ï¼Œæ ¹æ®æˆ‘ä»¬çš„å†…éƒ¨æµ‹è¯„ï¼Œä¼¼ä¹Žæš‚æœªæœ‰å¼€æºçš„é«˜æ€§èƒ½çš„ Triton ç‰ˆæœ¬çš„ W4A16 ç®—å­å®žçŽ°ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ä¸ªå€¼å¾—æŽ¢ç´¢çš„æ–¹å‘ã€‚

åœ¨é‡åŒ–å±‚é¢ï¼Œæˆ‘ä»¬éœ€è¦å†æ¬¡å¼ºè°ƒ GPTQ æ–¹æ³•åªå¯¹æ¨¡åž‹æƒé‡è¿›è¡Œé‡åŒ–ã€‚è€Œé’ˆå¯¹å¤§è¯­è¨€æ¨¡åž‹çš„é‡åŒ–ï¼Œå­˜åœ¨å…¶ä»–çš„æ–¹æ³•ï¼Œæä¾›äº†ä»¥è¾ƒå°çš„é¢„æµ‹è´¨é‡æŸå¤±ä¸ºä»£ä»·ï¼ŒåŒæ—¶é‡åŒ–æƒé‡å’Œæ¿€æ´»å€¼çš„æ–¹æ¡ˆã€‚å¦‚ [LLM-QAT](https://arxiv.org/pdf/2305.17888.pdf) é‡‡ç”¨ int4/int8 çš„æ··åˆç²¾åº¦æ–¹æ¡ˆï¼ŒåŒæ—¶è¿˜å¯¹ KV Cache æ–½è¡Œé‡åŒ–ã€‚è¿™ä¸€æŠ€æœ¯çš„å¼ºå¤§ä¼˜ç‚¹æ˜¯èƒ½å®žé™…ä½¿ç”¨æ•´æ•°è¿ç®—ç®—æ³•æ¥è¿›è¡Œè®¡ç®—ï¼Œä¸€ä¸ªä¾‹å­æ˜¯ [è‹±ä¼Ÿè¾¾çš„å¼ é‡æ ¸å¿ƒæ”¯æŒ int8 è®¡ç®—](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf) ã€‚ç„¶è€Œï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œç›®å‰æš‚æ— å¼€æºçš„ W4A8 é‡åŒ–ç®—å­ï¼Œä½†è¿™å¯èƒ½æ˜¯ä¸€ä¸ª [å€¼å¾—æŽ¢ç´¢çš„æ–¹å‘](https://www.qualcomm.com/news/onq/2023/04/floating-point-arithmetic-for-ai-inference-hit-or-miss) ã€‚

åœ¨ç®—å­å±‚é¢ï¼Œä¸ºæ›´å¤§çš„æ‰¹å¤„ç†å¤§å°è®¾è®¡é«˜æ€§èƒ½çš„ W4A16 ç®—å­ä»ç„¶æ˜¯ä¸€å¤§æŒ‘æˆ˜ã€‚

### å·²æ”¯æŒçš„æ¨¡åž‹

åœ¨åˆå§‹å®žçŽ°ä¸­ï¼Œæš‚æ—¶åªæ”¯æŒçº¯ç¼–ç å™¨æˆ–çº¯è§£ç å™¨æž¶æž„çš„å¤§è¯­è¨€æ¨¡åž‹ã€‚è¿™å¬èµ·æ¥ä¼¼ä¹Žæœ‰è¾ƒå¤§çš„å±€é™æ€§ï¼Œä½†å…¶å®žå·²ç»æ¶µç›–äº†å½“å‰ç»å¤§å¤šæ•°æœ€å…ˆè¿›çš„å¤§è¯­è¨€æ¨¡åž‹ï¼Œå¦‚ Llamaã€OPTã€GPT-Neoã€GPT-NeoX ç­‰ã€‚

å¤§åž‹çš„è§†è§‰ã€è¯­éŸ³å’Œå¤šæ¨¡æ€æ¨¡åž‹åœ¨çŽ°é˜¶æ®µæš‚ä¸è¢«æ”¯æŒã€‚

ç»“è®ºå’Œç»“è¯­
-----

æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº† Transformers å¯¹ [AutoGPTQ ä»£ç åº“](https://github.com/PanQiWei/AutoGPTQ) çš„é›†æˆï¼Œä½¿å¾—ç¤¾åŒºä¸­çš„ä»»ä½•äººéƒ½å¯ä»¥æ›´æ–¹ä¾¿åœ°åˆ©ç”¨ GPTQ æ–¹æ³•é‡åŒ–å¤§è¯­è¨€æ¨¡åž‹ï¼ŒåŠ©åŠ›ä»¤äººæ¿€åŠ¨çš„å¤§è¯­è¨€æ¨¡åž‹å·¥å…·å’Œåº”ç”¨çš„æž„å»ºã€‚

è¿™ä¸€é›†æˆæ”¯æŒè‹±ä¼Ÿè¾¾ GPU å’ŒåŸºäºŽ RoCm çš„ AMD GPUï¼Œè¿™æ˜¯å‘æ”¯æŒæ›´å¹¿æ³› GPU æž¶æž„çš„é‡åŒ–æ¨¡åž‹çš„æ™®æƒ åŒ–è¿ˆå‡ºçš„ä¸€å¤§æ­¥ã€‚

ä¸Ž AutoGPTQ å›¢é˜Ÿçš„åˆä½œéžå¸¸å¯Œæœ‰æˆæ•ˆï¼Œæˆ‘ä»¬éžå¸¸æ„Ÿè°¢ä»–ä»¬çš„æ”¯æŒå’Œä»–ä»¬åœ¨è¯¥ä»£ç åº“ä¸Šçš„å·¥ä½œã€‚

æˆ‘ä»¬å¸Œæœ›æœ¬æ¬¡é›†æˆå°†ä½¿æ¯ä¸ªäººéƒ½æ›´å®¹æ˜“åœ°åœ¨ä»–ä»¬çš„åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨å¤§è¯­è¨€æ¨¡åž‹ï¼Œæˆ‘ä»¬è¿«ä¸åŠå¾…åœ°æƒ³è¦çœ‹åˆ°å¤§å®¶å³å°†ä½¿ç”¨å®ƒæ‰€åˆ›é€ å‡ºçš„ä¸€åˆ‡ï¼

å†æ¬¡æé†’ä¸è¦é”™è¿‡æ–‡ç« å¼€å¤´åˆ†äº«çš„æœ‰ç”¨èµ„æºï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£æœ¬æ¬¡é›†æˆçš„ç‰¹æ€§ä»¥åŠå¦‚ä½•å¿«é€Ÿå¼€å§‹ä½¿ç”¨ GPTQ é‡åŒ–ã€‚

*   [åŽŸå§‹è®ºæ–‡](https://arxiv.org/pdf/2210.17323.pdf)
*   [è¿è¡ŒäºŽ Google Colab ç¬”è®°æœ¬ä¸Šçš„åŸºç¡€ç”¨ä¾‹](https://colab.research.google.com/drive/1_TIrmuKOFhuRRiTWN94iLKUFu6ZX4ceb?usp=sharing) â€”â€” è¯¥ç¬”è®°æœ¬ä¸Šçš„ç”¨ä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ GPTQ æ–¹æ³•é‡åŒ–ä½ çš„ transformers æ¨¡åž‹ã€å¦‚ä½•è¿›è¡Œé‡åŒ–æ¨¡åž‹çš„æŽ¨ç†ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨é‡åŒ–åŽçš„æ¨¡åž‹è¿›è¡Œå¾®è°ƒã€‚
*   Transformers ä¸­é›†æˆ GPTQ çš„ [è¯´æ˜Žæ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/main_classes/quantization)
*   Optimum ä¸­é›†æˆ GPTQ çš„ [è¯´æ˜Žæ–‡æ¡£](https://huggingface.co/docs/optimum/llm_quantization/usage_guides/quantization)
*   TheBloke [æ¨¡åž‹ä»“åº“](https://huggingface.co/TheBloke?sort_models=likes#models) ä¸­çš„ GPTQ æ¨¡åž‹ã€‚

è‡´è°¢
--

æ„Ÿè°¢ [æ½˜å…¶å¨](https://github.com/PanQiWei) å¯¹æ°å‡ºçš„ AutoGPTQ ä»£ç åº“çš„æ”¯æŒå’Œæ‰€ä½œçš„å·¥ä½œï¼Œä»¥åŠä»–å¯¹æœ¬æ¬¡é›†æˆçš„å¸®åŠ©ã€‚  
æ„Ÿè°¢ [TheBloke](https://huggingface.co/TheBloke) ä½¿ç”¨ AutoGPTQ é‡åŒ–å¤§é‡çš„æ¨¡åž‹å¹¶åˆ†äº«åœ¨ Hugging Face Hub ä¸Šï¼Œä»¥åŠä»–åœ¨æœ¬æ¬¡é›†æˆä¸­æ‰€æä¾›çš„å¸®åŠ©ã€‚  
æ„Ÿè°¢ [qwopqwop200](https://github.com/qwopqwop200) å¯¹ AutoGPTQ ä»£ç åº“çš„æŒç»­è´¡çŒ®ï¼Œç›®å‰ï¼Œä»–æ­£è‡´åŠ›äºŽå°†è¯¥ä»£ç åº“çš„ä½¿ç”¨åœºæ™¯æ‹“å±•è‡³ CPU ï¼Œè¿™ä¸€ç‰¹æ€§å°†åœ¨ AutoGPTQ çš„ä¸‹ä¸€ç‰ˆæœ¬ä¸­å‘å¸ƒã€‚

æœ€åŽï¼Œæˆ‘ä»¬è¿˜è¦æ„Ÿè°¢ [Pedro Cuenca](https://github.com/pcuenca) å¯¹æœ¬æ–‡çš„æ’°å†™æ‰€æä¾›çš„å¸®åŠ©ã€‚

* * *

> è‹±æ–‡åŽŸæ–‡: [https://hf.co/blog/gptq-integration](https://hf.co/blog/gptq-integration)
> 
> åŽŸæ–‡ä½œè€…: Marc Sun, FÃ©lix Marty, æ½˜å…¶å¨, Junjae Lee, Younes Belkada, Tom Jobbins
> 
> è¯‘è€…: æ½˜å…¶å¨
> 
> å®¡æ ¡/æŽ’ç‰ˆ: zhongdongy (é˜¿ä¸œ)