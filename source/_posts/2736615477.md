---
layout: post
title: "Hadoop环境安装与配置"
date: "2023-09-06T00:56:46.868Z"
---
Hadoop环境安装与配置
=============

**1.基础操作系统环境安装（略）**
===================

**2.JDK的安装与配置**

当前各大数据软件如Hadoop等，仍然停留在Java 8上，在本实验选用的是Java 8。在自己的Linux系统中，jdk可以使用如下命令进行一键安装(需具备sudo权限)。

sudo  yum  install  java-1.8.0\-openjdk

sudo  yum  install  java-1.8.0\-openjdk-devel 

　　　　执行完命令后直接选择**y**

待安装完成后，需通过如下命令，检查java（jdk）是否安装成功

java  -version

javac  \-version

以下为检测情况：

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905214100200-90882329.png)

**3.Hadoop编译版本的下载，解压，并放置到相应目录中**
================================

　　**注意：**在接下来的操作中需将用户切换至Hadoop用户下

*   ### **添加Hadoop****专用的用户**
    

在进行Hadoop配置前是需先添加一个Hadoop专用的用户，操作Hadoop系统（含安装、配置，提交计算任务等），一般给该用户配置sudo权限，以便于配置过程中执行一些高权限的操作。以下设置该用户名为hadoop，可以进行如下操作：

sudo  useradd  -s  /bin/bash  -m  hadoop

sudo  passwd   hadoop

sudo  usermod  -aG  wheel  hadoop

按照提示输入即可（注意虽然密码长度不足8位，会出现警告，但是仍然可以设置）

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905214030739-1672276585.png)

上图操作命令分别对应添加Hadoop用户、设置密码和给予sudo权限。

*   ### **生成****SSH****密钥、配置SSH免密登录**
    

无论单节点的伪分布式部署，还是3节点的完全分布式部署，均需要配置SSH免密登录。配置免密登录需进行以下两步：

2.1.生成当前用户的密钥

ssh-keygen  -t  rsa

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905214011086-1633234600.png)

上图中所有步骤均直接按回车即可。

*   ### **将生成的公钥安装到目标服务器上**
    

ssh-copy-id  用户名@目标服务器的IP，按照提示输入密码等

例如，安装到本机当前用户（hadoop）

ssh\-copy-id  hadoop@localhost

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213951734-1352245340.png)

图中红框部分输入yes，其余按提示完成即可。

*   **安装wget工具（Linux系统下的下载工具）**
    ---------------------------
    

具体操作命令如下：

sudo  yum  install   wget

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213815534-640634904.png)

这里直接选择y即可。

*   ### **Hadoop伪分布式安装**
    

### （1）下载安装包

wget  https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.10.1/hadoop-2.10.1.tar.gz

　　![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213753804-1229336568.png)

这里直接根据命令下载即可。

### （2） 解压文件并放置到适当的位置  

一般将用户自己安装的程序放在/usr/local/目录下，为了便于管理，我们统一创建/usr/local/bda/目录，并将此目录（及其子目录）的所有者改为hadoop

sudo  mkdir  /usr/local/bda

sudo  chown  -R  hadoop:hadoop  /usr/local/bda

cd  ~  # 切换回hadoop用户的home目录

tar  xzvf  hadoop-2.10.1.tar.gz   

注意：如果提示找不到 tar 命令，则需要先安装，如下面命令所示：

sudo  yum  install  tar

 ![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213603535-364646953.png)

将解压后的文件夹移动到/usr/local/bda/目录下，并改名为hadoop

mv  ~/hadoop-2.10.1  /usr/local/bda/hadoop

**4.Hadoop环境的配置**
=================

Hadoop 2.x主要由HDFS、yarn、MapReduce三部分组成，因此总共有5个文件需要进行配置，分别是：

（1） hadoop-env.sh： Hadoop运行环境

（2） core-site.xml： 集群全局参数

（3） hdfs-site.xml： HDFS的配置

（4） yarn-site.xml： 集群资源管理系统参数

（5） mapred-site.xml：MapReduce的参数

需要说明的是：在执行完本节（4.3）的配置后，实际上完成的是整个Hadoop的配置（含MapReduce、YARN）而不仅仅是HDFS的配置。

*   **建立Hadoop所需的目录**

因为HDFS、MapReduce正常工作，需要一些专用的目录的辅助。因此在开始配置之前，需要建立相应的文件夹，操作如下：

mkdir  /usr/local/bda/hadoop/tmp

mkdir  /usr/local/bda/hadoop/var

mkdir  /usr/local/bda/hadoop/dfs

mkdir  /usr/local/bda/hadoop/dfs/name

mkdir  /usr/local/bda/hadoop/dfs/data

*   **配置hadoop-env.sh**

Hadoop系统环境，只需要配置一个环境变量：JAVA\_HOME，也就是告诉Hadoop系统，java的安装位置，使用如下命令打开配置文件：

vim  /usr/local/bda/hadoop/etc/hadoop/hadoop-env.sh

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905203820053-1872995303.png)

进行如下修改，然后保存、退出（：wq）。

*    **配置core-site.xml**

vim  /usr/local/bda/hadoop/etc/hadoop/core-site.xml

添加到core-site.xml文件configuration中的内容如下：

<property>
        <name>hadoop.tmp.dir</name>
        <value>/usr/local/bda/hadoop/tmp</value>
        <description>A base for other temporary directories.</description>
</property>
<property>
        <name>fs.default.name</name>
        <value>hdfs://localhost:9000</value>
</property>

说明：此处进行了两项配置，（1）配置了hadoop的临时目录；（2）配置了文件系统缺省的主机和端口。因为是伪分布式系统，所以此处的主机名是localhost

*   **配置hdfs-site.xml**

vim  /usr/local/bda/hadoop/etc/hadoop/hdfs-site.xml

进行如下图的配置，各项的说明见下图中的红字，保存，退出

 ![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213416091-1255159525.png)

*   **配置****mapred-site.xml**

首先，将mapred\-site.xml的配置模板文件mapred\-site.xml.template复制一份，并命名为mapred-site.xml

 ![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213351818-69902237.png)

然后用vim打开进行编辑

vim  /usr/local/bda/hadoop/etc/hadoop/mapred-site.xml

配置内容如下图所示，保存、退出

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213249745-1185712664.png)

*   **配置yarn-site.xml**

vim  /usr/local/bda/hadoop/etc/hadoop/yarn-site.xml

 ![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213157257-156793659.png)

配置内容如下图所示，保存、退出

<property>

        <name>yarn.nodemanager.aux-services</name>

        <value>mapreduce\_shuffle</value>

</property>

<property>

        <name>yarn.nodemanager.env\-whitelist</name>

        <value>JAVA\_HOME,HADOOP\_COMMON\_HOME,HADOOP\_HDFS\_HOME,HADOOP\_CONF\_DIR,CLASSPATH\_PREPEND\_DISTCACHE,HADOOP\_YARN\_HOME,HADOOP\_HOME,PATH,LANG,TZ,HADOOP\_MAPRED\_HOME</value>

</property>

<property>

        <name>yarn.nodemanager.resource.memory-mb</name>

        <value>2048</value>

</property>

<property>

        <name>yarn.nodemanager.vmem-check-enabled</name>

        <value>false</value>

</property>

5.**Hadoop环境的验证**
=================

### **5.1****.****HDFS文件系统格式化及服务启动、关闭**

5.1.1. HDFS文件系统格式化

如同其它的文件系统一样，HDFS在使用之前也要先进行格式化操作，使用如下的命令进行：

/usr/local/bda/hadoop/bin/hdfs  namenode  -format

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213116244-1694600884.png)

执行HDFS文件系统格式化命令后，会有较大的输出信息，可以检查是否有ERROR信息。

5.1.2. 启动HDFS服务及验证

(1) 输入如下命令，启动dfs服务       

 /usr/local/bda/hadoop/sbin/start-dfs.sh

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905212943210-759274964.png)

需要注意的是首次启动时，需要输入yes。其后再次启动则无需输入。

（2）输入 jps 命令，查看相关进程是否正常

 ![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213000782-1738045593.png)

jps命令的作用是查看当前系统中正在运行的java进程。如图15所示，执行完start-dfs.sh脚本后正常情况下有3个HDFS的进程，一个是NameNode进程，一个是DataNode进程，还有一个是SecondaryNameNode进程。除此之外还有jps进程自己。

（3）访问hdfs的http服务端口

HDFS提供了http服务端口，可以通过浏览器访问，但是需要注意的是，为了访问该端口，需要在防火墙上打开该端口，或者直接关闭防火墙。

检查防火墙状态  

sudo systemctl status firewalld

禁用防火墙  

sudo systemctl status firewalld

关闭防火墙  

sudo systemctl stop firewalld  

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905213047804-1199889927.png)

关闭防火墙端口后，就可以在windows系统打开浏览器，地址栏中输入虚拟机的“小网IP”及HDFS的http服务端口（2.x版本是50070）

如：[192.168.233.128:50070](http://192.168.233.128:50070)

 ![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905212848157-884696287.png)

5.1.3. 停止HDFS服务

注意：在关闭服务器之前，一定要先使用stop-dfs.sh命令停止HDFS文件系统，如果不执行该命令，直接进行服务器的关机操作，则HDFS系统很容易受到损坏。

 ![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905212702911-1723810158.png)

### **5.2.YARN服务启动及关闭**

与HDFS类似，Hadoop提供了YARN服务的启动（start-yarn.sh）和关闭（stop-yarn.sh）命令。需要注意的是，YARN服务一般在HDFS服务启动后启动，并在HDFS服务关闭之前关闭。其执行顺序一般是：

start-dfs.sh →start-yarn.sh →stop-yarn.sh →stop-dfs.sh

 ![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905212610084-859032631.png)

![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905212624215-1605593260.png)

与HDFS类似，也可以通过浏览器输入服务器的小网IP+8088端口，访问YARN的http服务，查看在执行的计算任务及系统资源情况（需要打开防火墙端口，或者关闭防火墙）

 ![](https://img2023.cnblogs.com/blog/3179434/202309/3179434-20230905205657865-1820026956.png)

 (注：请各位大佬手下留情，有不足的地方请指出！！)