---
layout: post
title: "【升职加薪秘籍】我在服务监控方面的实践(2)-监控组件配置"
date: "2023-07-26T01:12:05.407Z"
---
【升职加薪秘籍】我在服务监控方面的实践(2)-监控组件配置
=============================

> 大家好,我是蓝胖子，关于性能分析的视频和文章我也大大小小出了有一二十篇了，算是已经有了一个系列，之前的代码已经上传到 github.com/HobbyBear/performance-analyze ，接下来这段时间我将在之前内容的基础上，结合自己在公司生产上构建监控系统的经验，详细的展示如何对线上服务进行监控，内容涉及到的指标设计，软件配置，监控方案等等你都可以拿来直接复刻到你的项目里，这是一套非常适合中小企业的监控体系。

在上一节我们其实是建立起了对监控的概念，对监控什么，如何监控有了大致的印象。这一节我们就要正式开始动手实践了，这一节我会介绍下项目代码的结构以及着重介绍下其中docker-compose的配置文件。

完整代码我已经上传到了github

    github.com/HobbyBear/easymonitor
    

为了后面章节的介绍更加清晰，我在这一节还是介绍下整个项目各个目录以及含义

    (base) ➜  easymonitor git:(main) ✗ tree -L 1
    .
    ├── ReadMe.md
    ├── build.sh // 对webhookserver 以及 webapp 项目进行编译 ，然后放到program文件夹里
    ├── docker-compose.yaml // 启动各个监控系统组件
    ├── filebeat.yml // filebeat日志采集的配置文件
    ├── go.mod
    ├── go.sum
    ├── grafanadashbord // 放置grafana的监控面板导出的json文件，可直接启动项目，然后导入json文件，即可构建监控面板
    ├── infra // 项目基础组件的代码，因为服务的监控有时会涉及到埋点和prometheus client暴露指标，将这部分逻辑都写在这个包下，后续新应用只要引入这个包就能拥有这些监控指标
    ├── logconf // 放置主机上的日志采集配置文件，filebeat.yml 中会引入这个文件夹下的配置规则做不同的采集策略
    ├── logs // 放置应用服务日志的目录，由于是docker-compose启动，需要将主机这个目录同时映射到filebeat和应用服务容器，filebeat会对这个目录下的日志进行采集
    ├── logstash.conf // logstash 配置文件
    ├── program // 放置webhookserver 以及 webapp 项目编译好的二进制文件
    ├── prometheus.yml // prometheus 配置文件
    ├── webapp // 应用服务代码
    └── alerterserver // 模拟自研报警系统代码
    

由于机器有限，我准备用docker-compose来构建我们需要用到的监控组件以及应用服务。回顾下监控架构图。

![image.png](https://img2023.cnblogs.com/blog/1382767/202307/1382767-20230725151512881-1076049083.png)

我们需要的组件或者服务有，应用服务(在项目代码里是webapp)，filebeat，prometheus，logstash，elasticsearch，kibana, grafana，node exporter ， 自研的报警服务(在项目代码里是alerterserver)

可以看到，在实际的生产环境中，应用服务和filebeat，node exporter是在同一台主机上，共享了linux命名空间，直接用docker-compose 启动各个组件不好模拟这种情况，所以为了更加真实的模拟，**我对node exporter 启动容器的配置做了简单修改，让项目代码里的logs目录同时映射到filebeat容器和node exporter容器内部，并且让应用程序代码在node exporter容器里启动，这样filebeat从logs目录采集到的日志就是应用程序webapp打的日志了**。

为了让node exporter 容器镜像启动时也会运行webapp程序，我修改了其启动容器时的entrypoint配置，因为node exporter本来的entrypoint是要去运行node exporter进程的，现在修改为要运行一个脚本。

    version: "3.7"  
    services:  
      mynode:  
        image: prom/node-exporter:latest  
        container_name: "node0"  
        hostname: "mynode"  
        ports:  
          - "9100:9100"  
          - "8080:8080"  
          - "8090:8090"  
        volumes:  
          - "./program:/program"  
          - "./logs:/logs"  
        restart: always  
        entrypoint: "sh /program/start_node_exporter.sh"  
    

脚本内则是将webapp和node exporter同时启动起来，脚本是放置在项目program 目录里，映射到了 容器内部。 webapp通过8090端口暴露prometheus 指标信息，通过8080端口监听http请求。9100端口是node exporter服务监听的端口。脚本内容如下:

    #!/bin/bash  
    nohup  /program/webapp &  
    node_exporter  --collector.vmstat --collector.tcpstat --collector.processes
    

docker-compose 配置
-----------------

完整的 docker-compose 配置文件如下:

    version: "3.7"  
    services:  
      mynode:  
        image: prom/node-exporter:latest  
        container_name: "node0"  
        hostname: "mynode"  
        ports:  
          - "9100:9100"  
          - "8080:8080"  
          - "8090:8090"  
        volumes:  
          - "./program:/program"  
          - "./logs:/logs"  
        restart: always  
        entrypoint: "sh /program/start_node_exporter.sh"  
      
      
      prometheus:  
        image: prom/prometheus:latest  
        container_name: "prometheus0"  
        restart: always  
        ports:  
          - "9090:9090"  
        volumes:  
          - "./prometheus.yml:/etc/prometheus/prometheus.yml"  
      grafana:  
        image: grafana/grafana  
        container_name: "grafana0"  
        ports:  
          - "3000:3000"  
        restart: always  
      elasticsearch:  
        image: docker.elastic.co/elasticsearch/elasticsearch:7.14.2  
        container_name: elasticsearch  
        environment:  
          - discovery.type=single-node  
          - "ES_JAVA_OPTS=-Xms512m -Xmx512m"  
        ports:  
          - "9200:9200"  
      kibana:  
        image: docker.elastic.co/kibana/kibana:7.14.2  
        container_name: kibana  
        ports:  
          - "5601:5601"  
        environment:  
          ELASTICSEARCH_URL: http://elasticsearch:9200  
      filebeat:  
        image: docker.elastic.co/beats/filebeat:7.14.2  
        container_name: filebeat  
        user: root  
        volumes:  
          - ./logs:/logs  
          - ./logconf:/logconf  
          - ./filebeat.yml:/usr/share/filebeat/filebeat.yml  
        command: filebeat -e -d "*"  
        depends_on:  
          - elasticsearch  
          - logstash  
      
      logstash:  
        image: docker.elastic.co/logstash/logstash:7.14.2  
        volumes:  
          - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf  
        ports:  
          - "5044:5044"  
        depends_on:  
          - elasticsearch  
        mem_reservation: 1000M  
        cpu_count: 1  
      ubuntu:  
        image: ubuntu  
        command: ./alerterserver 
        ports:  
          - "16060:16060"  
        volumes:  
          - "./program:/program"  
        working_dir: /program  
      mydb:  
        restart: always  
        image: amd64/mysql:latest  
        container_name: mydb  
        environment:  
          - "MYSQL_ROOT_PASSWORD=1234567"  
          - "MYSQL_DATABASE=test"  
        ports:  
          - "3306:3306"
    

需要注意的是其中**卷映射**的配置，我们挨个来看下映射了哪些配置文件。

首先是prometheus 将项目代码里的prometheus.yml 映射到prometheus容器内部，prometheus.yml 里面配置要采集的对象，如下所示，我们需要对主机以及应用服务进行指标采集。

    ## prometheus.yml
    global:  
      scrape_interval:     15s # 默认抓取周期  
    scrape_configs:  
      - job_name: 'normal'  ## 对node exporter 进行采集
        scrape_interval: 5s  
        metrics_path: /metrics  
        static_configs:  
          - targets: ['mynode:9100']  
      
      - job_name: 'webapp'  ## 对应用服务指标进行采集
        scrape_interval: 5s  
        metrics_path: /metrics  
        static_configs:  
          - targets: [ 'mynode:8090' ]  
        relabel_configs:  
          - source_labels: [ __address__ ]  
            target_label: instance  
            regex: (.*):\d+  
            replacement: $1
    

然后是filebeat，映射了3个卷，分别是项目代码里的logs目录，这个目录是filebeat的采集日志目录，filebeat配置的采集规则将从这个目录采集日志。配置的规则放到了logconf目录下，以下是配置规则文件示例:

    ##  logconf/api.yml
    - type: log  
      tail_files: true   // 该配置为true，为了让filebeat启动的时候对新增的日志才进行采集，对历史日志不进行采集
      paths:  
        - /logs/**.log  
      fields:  
        log_type: project1
    

除此以外，filebeat还将项目代码里的filebeat.yml 配置文件映射到了filebeat容器内。

接着是logstash 容器配置，它映射了项目代码里的logstash 配置文件，这个文件主要是定义了一些日志清洗规则，已经定义日志的输入来源和输出来源，在这个系统里，输入来源就是filebeat，输出来源就是elasticsearch。

然后是ubuntu这个容器，映射了项目代码里的program 目录，program这个目录下放置了alerterserver报警服务的二进制程序，ubuntu容器就是前台启动这个程序，16060端口就是报警服务监听的端口。

启动监控系统
------

通过下面两个命令，我们就可以启动整个监控系统

    (base) ➜  easymonitor git:(main) ✗ sh build.sh
    (base) ➜  easymonitor git:(main) ✗ docker-compose up
    

配置数据源
-----

接着，服务启动之后，在浏览器输入 localhost:3000就可以 访问grafana的界面了，默认账号和密码都是admin，点击左边菜单栏选择Data sources 。

![2181688956424_.pic.jpg](https://img2023.cnblogs.com/blog/1382767/202307/1382767-20230725151513170-1738395588.jpg)

注意prometheus的的ip地址要换成你本地机器局域的ip，因为docker-compose启动的每个容器拥有各自的网络命名空间，要访问其他容器的进程，就得用容器的ip+端口，不过我们本地机器映射了相同端口且容器和本地机器是互通的，所以ip地址填成本地机器局域网ip即可。

> 你也可以用prometheus关键字替换ip地址，变成http://prometheus:9090 ，因为docker-compose启动的进程默认可以用配置文件中的容器名代替ip地址进行访问。

配置好数据源以后，就可以正式对系统进行监控了，正如前一节[【升职加薪秘籍】我在服务监控方面的实践(1)-监控蓝图](https://mp.weixin.qq.com/s/DDvk6H_SNMI5sXbOl7Gk-g) 所说，监控是分级的，所以我们建立监控系统指标时，也是这样，在下一节，我会首先介绍如何在操作系统，服务器层面建立起系统的监控，并定制一个自己的dash board。

在万千人海中，相遇就是缘分，为了这份缘分，给作者点个赞👍🏻不过分吧。