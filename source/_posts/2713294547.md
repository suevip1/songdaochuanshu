---
layout: post
title: "从Google开发者大会浅谈LLM的应用"
date: "2023-09-11T00:57:14.706Z"
---
从Google开发者大会浅谈LLM的应用
====================

![从Google开发者大会浅谈LLM的应用](https://img2023.cnblogs.com/blog/599309/202309/599309-20230910174757644-1365008265.png) 浅谈Google开发者大会提到的LLM的应用

这周参加了在上海世博中心举办Google I/O Connect中国开发者大会，有几年没参加这么高质量的活动，有点感慨。

![](https://img2023.cnblogs.com/blog/599309/202309/599309-20230910173653001-1018863220.jpg)

    期间重点听了关于GCP和Google AI大语言模型的主题演讲，发现目前各大厂商仍然还处于大语言模型的早期应用阶段，Google PaLM 2也不例外。作为业界最领先的AI公司之一，PaLM是OpenAI ChatGPT系列模型的直接竞争对手，同样是目前业界公认的LLM最高技术水平的代表。这次大会生成式AI和LLM成为重点内容，也是这波浪潮的体现。

![](https://img2023.cnblogs.com/blog/599309/202309/599309-20230910174351161-2124839283.jpg)

　　根据官方介绍，PaLM 2模型擅长高级推理任务，包括编程和数学，分类和问题回答，翻译和多语种处理以及更好的自然语言生成能力，比Google之前最先进的LLM，包括PaLM更好。PaLM模型的核心技术和GPT模型一样都是基于划时代的Transformer架构的深度神经网络模型，其他开源LLM和国产若干LLM也是一样。可以说，2018年横空出世的Transformer架构是当前LLM浪潮的基础和底层核心架构。

![](https://img2023.cnblogs.com/blog/599309/202309/599309-20230910174244070-2060139954.png)

Transformer架构

**LLM的应用**

    同微软一样，Google也在其云平台提供了LLM的SaaS服务，分别是Vertex AI和Gen AI Studio, 从使用逻辑和UI界面上看，两家厂商都比较类似，提供的功能也大同小异。

![](https://img2023.cnblogs.com/blog/599309/202309/599309-20230910174517944-1186407609.png)

Google Gen AI Studio界面

![](https://img2023.cnblogs.com/blog/599309/202309/599309-20230910174538946-925603004.png)

微软Azure OpenAI Studio界面

    从云服务的设计和用法上看，二者的区别不大。针对LLM的应用场景，同样类似，这反映了目前LLM技术在商业落地上仍处于早期探索阶段。大会提到的应用场景主要以下几种：

*   行业/企业知识问答
    
*   搜索增强
    
*   流程自动化
    
*   代码生成
    

![](https://img2023.cnblogs.com/blog/599309/202309/599309-20230910174615371-1570335644.jpg)

    行业知识AI或者搜索增强场景是目前大语言模型落地的普遍切入点，核心技术是利用向量数据搜索内部知识库，将检索到的关联上下文同问题一起提交给LLM，由此得出更精确的回答和更高的内容质量。该场景技术成熟，相关的开源框架如Langchain，Semetic kenerl都有了现成的实现，只需要接入LLM模型的API即可实现功能。

![](https://img2023.cnblogs.com/blog/599309/202309/599309-20230910174643814-1394561335.png)

    我个人本次最感兴趣的场景是LLM流程自动化，Google此次演示了基于LLM自动化k8s集群的运维工作，能够让任何人都通过自然语言部署和维护k8s集群，这一点和AutoGPT的核心思路是一致的。

![](https://img2023.cnblogs.com/blog/599309/202309/599309-20230910174656685-1234495574.jpg)

LLM自动化运维k8s的实现流程

    具体操作流程如下：

1.  用户只需要在交互界面输入要执行的k8s操作，例如部署一个deployment
    
2.  LLM模型就会立刻生成k8s的yaml配置文件
    
3.  其壳程序会调用k8s api对生成的yaml配置或k8s命令进行多次校验，确认任务合法
    
4.  后台自动执行任务
    
5.  返回执行结果给用户UI
    

此类应用场景我相信会越来越多，不仅仅是自动化运维，可以为用户隐藏复杂的后台实现，通过简单的自然语言沟通就可以实现任何复杂的业务操作。极大地降低了各类任务中用户的操作门槛，对于提高各种产品和工具的生产力有很大帮助。

**总结**

    大语言模型LLM作为目前最热门的技术领域，预计随着越来越多企业场景的采用，会涌现出更多有价值，创新性的场景，下次碰到有意思的场景再和大家分享。