---
layout: post
title: "在树莓派上实现numpy的conv2d卷积神经网络做图像分类，加载pytorch的模型参数，推理mnist手写数字识别，并使用多进程加速"
date: "2023-05-31T01:16:55.312Z"
---
在树莓派上实现numpy的conv2d卷积神经网络做图像分类，加载pytorch的模型参数，推理mnist手写数字识别，并使用多进程加速
====================================================================

这几天又在玩树莓派，先是搞了个物联网，又在尝试在树莓派上搞一些简单的神经网络，这次搞得是卷积识别mnist手写数字识别

训练代码在电脑上，cpu就能训练，很快的：

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
import numpy as np

# 设置随机种子
torch.manual\_seed(42)

# 定义数据预处理
transform = transforms.Compose(\[
    transforms.ToTensor(),
    # transforms.Normalize((0.1307,), (0.3081,))
\])

# 加载训练数据集
train\_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)
train\_loader \= torch.utils.data.DataLoader(train\_dataset, batch\_size=64, shuffle=True)

# 构建卷积神经网络模型
class Net(nn.Module):
    def \_\_init\_\_(self):
        super(Net, self).\_\_init\_\_()
        self.conv1 \= nn.Conv2d(1, 10, kernel\_size=5)
        self.pool \= nn.MaxPool2d(2)
        self.fc \= nn.Linear(10 \* 12 \* 12, 10)

    def forward(self, x):
        x \= self.pool(torch.relu(self.conv1(x)))
        x \= x.view(-1, 10 \* 12 \* 12)
        x \= self.fc(x)
        return x

model \= Net()

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer \= optim.SGD(model.parameters(), lr=0.01, momentum=0.5)

# 训练模型
def train(model, device, train\_loader, optimizer, criterion, epochs):
    model.train()
    for epoch in range(epochs):
        for batch\_idx, (data, target) in enumerate(train\_loader):
            data, target \= data.to(device), target.to(device)
            optimizer.zero\_grad()
            output \= model(data)
            loss \= criterion(output, target)
            loss.backward()
            optimizer.step()
            if batch\_idx % 100 == 0:
                print(f'Train Epoch: {epoch+1} \[{batch\_idx \* len(data)}/{len(train\_loader.dataset)} '
                      f'({100. \* batch\_idx / len(train\_loader):.0f}%)\]\\tLoss: {loss.item():.6f}')

# 在GPU上训练（如果可用），否则使用CPU
device = torch.device("cuda" if torch.cuda.is\_available() else "cpu")
model.to(device)

# 训练模型
train(model, device, train\_loader, optimizer, criterion, epochs=5)

# 保存模型为NumPy数据
model\_state = model.state\_dict()
numpy\_model\_state \= {key: value.cpu().numpy() for key, value in model\_state.items()}
np.savez('model.npz', \*\*numpy\_model\_state)
print("Model saved as model.npz")

然后需要自己在dataset里导出一些图片：我保存在了mnist\_pi文件夹下,“\_”后面的是标签，主要是在pc端导出保存到树莓派下

![](https://img2023.cnblogs.com/blog/1376619/202305/1376619-20230530190412275-1593362907.png)

 **树莓派推理端的代码，需要numpy手动重新搭建网络，并且需要手动实现conv2d卷积神经网络和maxpool2d最大池化，然后加载那些保存的矩阵参数，做矩阵乘法和加法**

import numpy as np
import os
from PIL import Image

def conv2d(input, weight, bias, stride=1, padding=0):
    batch\_size, in\_channels, in\_height, in\_width \= input.shape
    out\_channels, in\_channels, kernel\_size, \_ \= weight.shape

    # 计算输出特征图的大小
    out\_height = (in\_height + 2 \* padding - kernel\_size) // stride + 1
    out\_width \= (in\_width + 2 \* padding - kernel\_size) // stride + 1

    # 添加padding
    padded\_input = np.pad(input, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')

    # 初始化输出特征图
    output = np.zeros((batch\_size, out\_channels, out\_height, out\_width))

    # 执行卷积操作
    for b in range(batch\_size):
        for c\_out in range(out\_channels):
            for h\_out in range(out\_height):
                for w\_out in range(out\_width):
                    h\_start \= h\_out \* stride
                    h\_end \= h\_start + kernel\_size
                    w\_start \= w\_out \* stride
                    w\_end \= w\_start + kernel\_size

                    # 提取对应位置的输入图像区域
                    input\_region = padded\_input\[b, :, h\_start:h\_end, w\_start:w\_end\]

                    # 计算卷积结果
                    x = input\_region \* weight\[c\_out\]
                    bia \= bias\[c\_out\]
                    conv\_result \= np.sum(x, axis=(0,1, 2)) + bia

                    # 将卷积结果存储到输出特征图中
                    output\[b, c\_out, h\_out, w\_out\] = conv\_result

    return output

def max\_pool2d(input, kernel\_size, stride=None, padding=0):
    batch\_size, channels, in\_height, in\_width \= input.shape

    if stride is None:
        stride \= kernel\_size

    out\_height \= (in\_height - kernel\_size + 2 \* padding) // stride + 1
    out\_width \= (in\_width - kernel\_size + 2 \* padding) // stride + 1

    padded\_input \= np.pad(input, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')

    output \= np.zeros((batch\_size, channels, out\_height, out\_width))

    for b in range(batch\_size):
        for c in range(channels):
            for h\_out in range(out\_height):
                for w\_out in range(out\_width):
                    h\_start \= h\_out \* stride
                    h\_end \= h\_start + kernel\_size
                    w\_start \= w\_out \* stride
                    w\_end \= w\_start + kernel\_size

                    input\_region \= padded\_input\[b, c, h\_start:h\_end, w\_start:w\_end\]

                    output\[b, c, h\_out, w\_out\] \= np.max(input\_region)

    return output

# 加载保存的模型数据
model\_data = np.load('model.npz')

# 提取模型参数
conv\_weight = model\_data\['conv1.weight'\]
conv\_bias \= model\_data\['conv1.bias'\]
fc\_weight \= model\_data\['fc.weight'\]
fc\_bias \= model\_data\['fc.bias'\]

# 进行推理
def inference(images):
    # 执行卷积操作
    conv\_output = conv2d(images, conv\_weight, conv\_bias, stride=1, padding=0)
    conv\_output \= np.maximum(conv\_output, 0)  # ReLU激活函数
    #maxpool2d
    pool = max\_pool2d(conv\_output,2)
    # 执行全连接操作
    flattened = pool.reshape(pool.shape\[0\], -1)
    fc\_output \= np.dot(flattened, fc\_weight.T) + fc\_bias
    fc\_output \= np.maximum(fc\_output, 0)  # ReLU激活函数

    # 获取预测结果
    predictions = np.argmax(fc\_output, axis=1)

    return predictions


folder\_path \= './mnist\_pi'  # 替换为图片所在的文件夹路径
def infer\_images\_in\_folder(folder\_path):
    for file\_name in os.listdir(folder\_path):
        file\_path \= os.path.join(folder\_path, file\_name)
        if os.path.isfile(file\_path) and file\_name.endswith(('.jpg', '.jpeg', '.png')):
            image \= Image.open(file\_path)
            label \= file\_name.split(".")\[0\].split("\_")\[1\]
            image \= np.array(image)/255.0
            image \= np.expand\_dims(image,axis=0)
            image \= np.expand\_dims(image,axis=0)
            print("file\_path:",file\_path,"img size:",image.shape,"label:",label)
            predicted\_class \= inference(image)
            print('Predicted class:', predicted\_class)

infer\_images\_in\_folder(folder\_path)

这代码完全就是numpy推理，不需要安装pytorch，树莓派也装不动pytorch，太重了，下面是推理结果，比之前的MLP网络慢很多，主要是手动实现的卷积网络全靠循环实现。

![](https://img2023.cnblogs.com/blog/1376619/202305/1376619-20230530190757935-417807504.png)

 那我们给它加加速吧，下面是一个多线程加速程序：

import numpy as np
import os
from PIL import Image
from multiprocessing import Pool

def conv2d(input, weight, bias, stride=1, padding=0):
    batch\_size, in\_channels, in\_height, in\_width \= input.shape
    out\_channels, in\_channels, kernel\_size, \_ \= weight.shape

    # 计算输出特征图的大小
    out\_height = (in\_height + 2 \* padding - kernel\_size) // stride + 1
    out\_width \= (in\_width + 2 \* padding - kernel\_size) // stride + 1

    # 添加padding
    padded\_input = np.pad(input, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')

    # 初始化输出特征图
    output = np.zeros((batch\_size, out\_channels, out\_height, out\_width))

    # 执行卷积操作
    for b in range(batch\_size):
        for c\_out in range(out\_channels):
            for h\_out in range(out\_height):
                for w\_out in range(out\_width):
                    h\_start \= h\_out \* stride
                    h\_end \= h\_start + kernel\_size
                    w\_start \= w\_out \* stride
                    w\_end \= w\_start + kernel\_size

                    # 提取对应位置的输入图像区域
                    input\_region = padded\_input\[b, :, h\_start:h\_end, w\_start:w\_end\]

                    # 计算卷积结果
                    x = input\_region \* weight\[c\_out\]
                    bia \= bias\[c\_out\]
                    conv\_result \= np.sum(x, axis=(0,1, 2)) + bia

                    # 将卷积结果存储到输出特征图中
                    output\[b, c\_out, h\_out, w\_out\] = conv\_result

    return output

def max\_pool2d(input, kernel\_size, stride=None, padding=0):
    batch\_size, channels, in\_height, in\_width \= input.shape

    if stride is None:
        stride \= kernel\_size

    out\_height \= (in\_height - kernel\_size + 2 \* padding) // stride + 1
    out\_width \= (in\_width - kernel\_size + 2 \* padding) // stride + 1

    padded\_input \= np.pad(input, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')

    output \= np.zeros((batch\_size, channels, out\_height, out\_width))

    for b in range(batch\_size):
        for c in range(channels):
            for h\_out in range(out\_height):
                for w\_out in range(out\_width):
                    h\_start \= h\_out \* stride
                    h\_end \= h\_start + kernel\_size
                    w\_start \= w\_out \* stride
                    w\_end \= w\_start + kernel\_size

                    input\_region \= padded\_input\[b, c, h\_start:h\_end, w\_start:w\_end\]

                    output\[b, c, h\_out, w\_out\] \= np.max(input\_region)

    return output

# 加载保存的模型数据
model\_data = np.load('model.npz')

# 提取模型参数
conv\_weight = model\_data\['conv1.weight'\]
conv\_bias \= model\_data\['conv1.bias'\]
fc\_weight \= model\_data\['fc.weight'\]
fc\_bias \= model\_data\['fc.bias'\]

# 进行推理
def inference(images):
    # 执行卷积操作
    conv\_output = conv2d(images, conv\_weight, conv\_bias, stride=1, padding=0)
    conv\_output \= np.maximum(conv\_output, 0)  # ReLU激活函数
    # maxpool2d
    pool = max\_pool2d(conv\_output, 2)
    # 执行全连接操作
    flattened = pool.reshape(pool.shape\[0\], -1)
    fc\_output \= np.dot(flattened, fc\_weight.T) + fc\_bias
    fc\_output \= np.maximum(fc\_output, 0)  # ReLU激活函数

    # 获取预测结果
    predictions = np.argmax(fc\_output, axis=1)

    return predictions

labels \= \[\]
preds \= \[\]
def infer\_image(file\_path):
    image \= Image.open(file\_path)
    label \= file\_path.split("/")\[-1\].split(".")\[0\].split("\_")\[1\]
    image \= np.array(image) / 255.0
    image \= np.expand\_dims(image, axis=0)
    image \= np.expand\_dims(image, axis=0)
    print("file\_path:", file\_path, "img size:", image.shape, "label:", label)
    predicted\_class \= inference(image)
    print('Predicted class:', predicted\_class)


folder\_path \= './mnist\_pi'  # 替换为图片所在的文件夹路径
pool = Pool(processes=4)  # 设置进程数为2，可以根据需要进行调整

def infer\_images\_in\_folder(folder\_path):
    for file\_name in os.listdir(folder\_path):
        file\_path \= os.path.join(folder\_path, file\_name)
        if os.path.isfile(file\_path) and file\_name.endswith(('.jpg', '.jpeg', '.png')):
            pool.apply\_async(infer\_image, args\=(file\_path,))

    pool.close()
    pool.join()


infer\_images\_in\_folder(folder\_path)

下图可以看出来，我的树莓派3b+，cpu直接拉满，速度提升4倍：

![](https://img2023.cnblogs.com/blog/1376619/202305/1376619-20230530191048114-822426442.png)

多思考也是一种努力，做出正确的分析和选择，因为我们的时间和精力都有限，所以把时间花在更有价值的地方。