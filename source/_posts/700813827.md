---
layout: post
title: "è¾…åŠ©ç”Ÿæˆï¼šä½Žå»¶è¿Ÿæ–‡æœ¬ç”Ÿæˆçš„æ–°æ–¹å‘"
date: "2023-05-26T01:07:25.284Z"
---
è¾…åŠ©ç”Ÿæˆï¼šä½Žå»¶è¿Ÿæ–‡æœ¬ç”Ÿæˆçš„æ–°æ–¹å‘
================

å¤§åž‹è¯­è¨€æ¨¡åž‹å¦‚ä»Šé£Žé¡ä¸€æ—¶ï¼Œè®¸å¤šå…¬å¸æŠ•å…¥å¤§é‡èµ„æºæ¥æ‰©å±•å®ƒä»¬è§„æ¨¡å¹¶è§£é”æ–°åŠŸèƒ½ã€‚ç„¶è€Œï¼Œä½œä¸ºæ³¨æ„åŠ›æŒç»­æ—¶é—´ä¸æ–­ç¼©çŸ­çš„äººç±»ï¼Œæˆ‘ä»¬å¹¶ä¸å–œæ¬¢å¤§æ¨¡åž‹ç¼“æ…¢çš„å“åº”æ—¶é—´ã€‚ç”±äºŽå»¶è¿Ÿå¯¹äºŽè‰¯å¥½çš„ç”¨æˆ·ä½“éªŒè‡³å…³é‡è¦ï¼Œäººä»¬é€šå¸¸ä½¿ç”¨è¾ƒå°çš„æ¨¡åž‹æ¥å®Œæˆä»»åŠ¡ï¼Œå°½ç®¡å®ƒä»¬çš„è´¨é‡è¾ƒä½Ž (ä¾‹å¦‚ [ä»£ç è¡¥å…¨ä»»åŠ¡](https://ai.googleblog.com/2022/07/ml-enhanced-code-completion-improves.html))ã€‚

ä¸ºä»€ä¹ˆæ–‡æœ¬ç”Ÿæˆè¿™ä¹ˆæ…¢ï¼Ÿæ˜¯ä»€ä¹ˆé˜»æ­¢ä½ åœ¨ä¸ç ´äº§çš„æƒ…å†µä¸‹éƒ¨ç½²ä½Žå»¶è¿Ÿå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼Ÿåœ¨è¿™ç¯‡åšæ–‡ä¸­ï¼Œæˆ‘ä»¬å°†é‡æ–°å®¡è§†è‡ªå›žå½’æ–‡æœ¬ç”Ÿæˆçš„ç“¶é¢ˆï¼Œå¹¶ä»‹ç»ä¸€ç§æ–°çš„è§£ç æ–¹æ³•æ¥è§£å†³å»¶è¿Ÿé—®é¢˜ã€‚ä½ ä¼šå‘çŽ°ï¼Œé€šè¿‡ä½¿ç”¨æˆ‘ä»¬çš„æ–°çš„è¾…åŠ©ç”Ÿæˆæ–¹æ³•ï¼Œä½ å¯ä»¥å°†ç¡¬ä»¶ä¸­çš„å»¶è¿Ÿé™ä½Žå¤šè¾¾ 10 å€ï¼

ç†è§£æ–‡æœ¬ç”Ÿæˆå»¶è¿Ÿ
--------

æ–‡æœ¬ç”Ÿæˆçš„æ ¸å¿ƒå¾ˆå®¹æ˜“ç†è§£ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æ ¸å¿ƒéƒ¨åˆ† (å³ ML æ¨¡åž‹)ï¼Œå®ƒçš„è¾“å…¥åŒ…å«ä¸€ä¸ªæ–‡æœ¬åºåˆ—ï¼Œå…¶ä¸­åŒ…æ‹¬åˆ°ç›®å‰ä¸ºæ­¢ç”Ÿæˆçš„æ–‡æœ¬ï¼Œä»¥åŠå…¶ä»–ç‰¹å®šäºŽæ¨¡åž‹çš„ç»„ä»¶ (ä¾‹å¦‚ Whisper è¿˜æœ‰ä¸€ä¸ªéŸ³é¢‘è¾“å…¥)ã€‚è¯¥æ¨¡åž‹æŽ¥å—è¾“å…¥å¹¶è¿›è¡Œå‰å‘ä¼ é€’: è¾“å…¥è¢«å–‚å…¥æ¨¡åž‹å¹¶ä¸€å±‚ä¸€å±‚é¡ºåºä¼ é€’ï¼Œç›´åˆ°é¢„æµ‹å‡ºä¸‹ä¸€ä¸ª token çš„éžæ ‡å‡†åŒ–å¯¹æ•°æ¦‚çŽ‡ (ä¹Ÿç§°ä¸º logits)ã€‚ä¸€ä¸ª token å¯èƒ½åŒ…å«æ•´ä¸ªè¯ã€å­è¯ï¼Œæˆ–è€…æ˜¯å•ä¸ªå­—ç¬¦ï¼Œè¿™å–å†³äºŽå…·ä½“æ¨¡åž‹ã€‚å¦‚æžœä½ æƒ³æ·±å…¥äº†è§£æ–‡æœ¬ç”Ÿæˆçš„åŽŸç†ï¼Œ[GPT-2 æ’å›¾](https://jalammar.github.io/illustrated-gpt2/) æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å‚è€ƒã€‚

![](https://devrel.andfun.cn/devrel/posts/2023-05-25-143908.png)

æ¨¡åž‹çš„å‰å‘ä¼ é€’æä¾›äº†ä¸‹ä¸€ä¸ª token çš„æ¦‚çŽ‡ï¼Œä½ å¯ä»¥è‡ªç”±æ“ä½œ (ä¾‹å¦‚ï¼Œå°†ä¸éœ€è¦çš„å•è¯æˆ–åºåˆ—çš„æ¦‚çŽ‡è®¾ç½®ä¸º 0)ã€‚æ–‡æœ¬ç”Ÿæˆçš„æ­¥éª¤å°±æ˜¯ä»Žè¿™äº›æ¦‚çŽ‡ä¸­é€‰æ‹©ä¸‹ä¸€ä¸ª tokenã€‚å¸¸è§çš„ç­–ç•¥åŒ…æ‹¬é€‰æ‹©æœ€æœ‰å¯èƒ½çš„ token (è´ªå¿ƒè§£ç )ï¼Œæˆ–ä»Žå®ƒä»¬çš„åˆ†å¸ƒä¸­æŠ½æ · (å¤šé¡¹å¼æŠ½æ ·)ã€‚åœ¨é€‰æ‹©äº†ä¸‹ä¸€ä¸ª token ä¹‹åŽï¼Œæˆ‘ä»¬å°†æ¨¡åž‹å‰å‘ä¼ é€’ä¸Žä¸‹ä¸€ä¸ª token è¿­ä»£åœ°è¿žæŽ¥èµ·æ¥ï¼Œç»§ç»­ç”Ÿæˆæ–‡æœ¬ã€‚è¿™ä¸ªè§£é‡Šåªæ˜¯è§£ç æ–¹æ³•çš„å†°å±±ä¸€è§’; è¯·å‚é˜…æˆ‘ä»¬ [å…³äºŽæ–‡æœ¬ç”Ÿæˆçš„åšå®¢](https://huggingface.co/blog/zh/how-to-generate) ä»¥è¿›è¡Œæ·±å…¥æŽ¢ç´¢ã€‚

![](https://devrel.andfun.cn/devrel/posts/2023-05-25-143912.png)

ä»Žä¸Šé¢çš„æè¿°ä¸­å¯ä»¥çœ‹å‡ºï¼Œæ–‡æœ¬ç”Ÿæˆçš„å»¶è¿Ÿç“¶é¢ˆå¾ˆæ˜Žæ˜¾: è¿è¡Œå¤§åž‹æ¨¡åž‹çš„å‰å‘ä¼ é€’å¾ˆæ…¢ï¼Œä½ å¯èƒ½éœ€è¦ä¾æ¬¡æ‰§è¡Œæ•°ç™¾æ¬¡è¿­ä»£ã€‚ä½†è®©æˆ‘ä»¬æ·±å…¥æŽ¢è®¨ä¸€ä¸‹: ä¸ºä»€ä¹ˆå‰å‘ä¼ é€’é€Ÿåº¦æ…¢ï¼Ÿå‰å‘ä¼ é€’é€šå¸¸ä»¥çŸ©é˜µä¹˜æ³•ä¸ºä¸»ï¼Œé€šè¿‡æŸ¥é˜…ç›¸åº”çš„ [ç»´åŸºç™¾ç§‘](https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm#Communication-avoiding_and_distributed_algorithms)ï¼Œä½ å¯ä»¥çœ‹å‡ºå†…å­˜å¸¦å®½æ˜¯æ­¤æ“ä½œçš„é™åˆ¶ (ä¾‹å¦‚ï¼Œä»Ž GPU RAM åˆ° GPU è®¡ç®—æ ¸å¿ƒ)ã€‚æ¢å¥è¯è¯´ï¼Œ _å‰å‘ä¼ é€’çš„ç“¶é¢ˆæ¥è‡ªå°†æ¨¡åž‹æƒé‡åŠ è½½åˆ°è®¾å¤‡çš„è®¡ç®—æ ¸å¿ƒä¸­ï¼Œè€Œä¸æ˜¯æ¥è‡ªæ‰§è¡Œè®¡ç®—æœ¬èº«_ã€‚

ç›®å‰ï¼Œä½ å¯ä»¥æŽ¢ç´¢ä¸‰ä¸ªä¸»è¦é€”å¾„æ¥å……åˆ†ç†è§£æ–‡æœ¬ç”Ÿæˆï¼Œæ‰€æœ‰è¿™äº›é€”å¾„éƒ½ç”¨äºŽè§£å†³æ¨¡åž‹å‰å‘ä¼ é€’çš„æ€§èƒ½é—®é¢˜ã€‚é¦–å…ˆï¼Œå¯¹äºŽç‰¹å®šç¡¬ä»¶çš„æ¨¡åž‹ä¼˜åŒ–ã€‚ä¾‹å¦‚ï¼Œå¦‚æžœä½ çš„è®¾å¤‡å¯èƒ½ä¸Ž [Flash Attention](https://github.com/HazyResearch/flash-attention) å…¼å®¹ï¼Œä½ å¯ä»¥ä½¿ç”¨å®ƒé€šå¯ä»¥è¿‡é‡æ–°æŽ’åºæ“ä½œæˆ– [INT8 é‡åŒ–](https://huggingface.co/blog/zh/hf-bitsandbytes-integration) æ¥åŠ é€Ÿæ³¨æ„åŠ›å±‚ï¼Œå…¶å‡å°‘äº†æ¨¡åž‹æƒé‡çš„å¤§å°ã€‚

å…¶æ¬¡ï¼Œå¦‚æžœä½ æœ‰å¹¶å‘æ–‡æœ¬ç”Ÿæˆéœ€æ±‚ï¼Œä½ å¯ä»¥å¯¹è¾“å…¥è¿›è¡Œæ‰¹å¤„ç†ï¼Œä»Žè€Œå®žçŽ°è¾ƒå°çš„å»¶è¿ŸæŸå¤±å¹¶å¤§å¹…å¢žåŠ åžåé‡ã€‚ä½ å¯ä»¥å°†æ¨¡åž‹å¯¹äºŽå¤šä¸ªè¾“å…¥å¹¶è¡Œè®¡ç®—ï¼Œè¿™æ„å‘³ç€ä½ å°†åœ¨å¤§è‡´ç›¸åŒçš„å†…å­˜å¸¦å®½è´Ÿæ‹…æƒ…å†µä¸‹èŽ·å¾—äº†æ›´å¤š tokenã€‚æ‰¹å¤„ç†çš„é—®é¢˜åœ¨äºŽä½ éœ€è¦é¢å¤–çš„è®¾å¤‡å†…å­˜ (æˆ–åœ¨æŸå¤„å¸è½½å†…å­˜)ã€‚ä½ å¯ä»¥çœ‹åˆ°åƒ [FlexGen](https://github.com/FMInference/FlexGen) è¿™æ ·çš„é¡¹ç›®ä»¥å»¶è¿Ÿä¸ºä»£ä»·æ¥ä¼˜åŒ–åžåé‡ã€‚

    # Example showcasing the impact of batched generation. Measurement device: RTX3090
    from transformers import AutoModelForCausalLM, AutoTokenizer
    import time
    
    tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
    model = AutoModelForCausalLM.from_pretrained("distilgpt2").to("cuda")
    inputs = tokenizer(["Hello world"], return_tensors="pt").to("cuda")
    
    def print_tokens_per_second(batch_size):
        new_tokens = 100
        cumulative_time = 0
    
        # warmup
        model.generate(
            **inputs, do_sample=True, max_new_tokens=new_tokens, num_return_sequences=batch_size
        )
    
        for _ in range(10):
            start = time.time()
            model.generate(
                **inputs, do_sample=True, max_new_tokens=new_tokens, num_return_sequences=batch_size
            )
            cumulative_time += time.time() - start
        print(f"Tokens per second: {new_tokens * batch_size * 10 / cumulative_time:.1f}")
    
    print_tokens_per_second(1) # Tokens per second: 418.3
    print_tokens_per_second(64) # Tokens per second: 16266.2 (~39x more tokens per second)
    

æœ€åŽï¼Œå¦‚æžœä½ æœ‰å¤šä¸ªå¯ç”¨è®¾å¤‡ï¼Œä½ å¯ä»¥ä½¿ç”¨ [Tensor å¹¶è¡Œ](https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many#tensor-parallelism) åˆ†é…å·¥ä½œè´Ÿè½½å¹¶èŽ·å¾—æ›´ä½Žçš„å»¶è¿Ÿã€‚ä½¿ç”¨ Tensor å¹¶è¡Œï¼Œä½ å¯ä»¥å°†å†…å­˜å¸¦å®½è´Ÿæ‹…åˆ†æ‘Šåˆ°å¤šä¸ªè®¾å¤‡ä¸Šï¼Œä½†é™¤äº†åœ¨å¤šä¸ªè®¾å¤‡è¿è¡Œè®¡ç®—çš„æˆæœ¬ä¹‹å¤–ï¼Œä½ è¿˜éœ€è¦è€ƒè™‘è®¾å¤‡é—´çš„é€šä¿¡ç“¶é¢ˆã€‚è¯¥æ–¹æ³•çš„æ”¶ç›Šåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºŽæ¨¡åž‹å¤§å°: å¯¹äºŽå¯ä»¥è½»æ¾åœ¨å•ä¸ªæ¶ˆè´¹çº§è®¾å¤‡ä¸Šè¿è¡Œçš„æ¨¡åž‹ï¼Œé€šå¸¸æ•ˆæžœå¹¶ä¸æ˜¾è‘—ã€‚æ ¹æ®è¿™ç¯‡ [DeepSpeed åšå®¢](https://www.microsoft.com/en-us/research/blog/deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression/)ï¼Œä½ ä¼šå‘çŽ°ä½ å¯ä»¥å°†å¤§å°ä¸º 17B çš„æ¨¡åž‹åˆ†å¸ƒåœ¨ 4 ä¸ª GPU ä¸Šï¼Œä»Žè€Œå°†å»¶è¿Ÿå‡å°‘ 1.5 å€ (å›¾ 7)ã€‚

è¿™ä¸‰ç§ç±»åž‹çš„æ”¹è¿›å¯ä»¥ä¸²è”ä½¿ç”¨ï¼Œä»Žè€Œäº§ç”Ÿ [é«˜é€šé‡è§£å†³æ–¹æ¡ˆ](https://github.com/huggingface/text-generation-inference)ã€‚ç„¶è€Œï¼Œåœ¨åº”ç”¨ç‰¹å®šäºŽç¡¬ä»¶çš„ä¼˜åŒ–åŽï¼Œé™ä½Žå»¶è¿Ÿçš„æ–¹æ³•æœ‰é™â€”â€”å¹¶ä¸”çŽ°æœ‰çš„æ–¹æ³•å¾ˆæ˜‚è´µã€‚è®©æˆ‘ä»¬æŽ¥ä¸‹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼

é‡æ–°å›žé¡¾è¯­è¨€æ¨¡åž‹è§£ç å™¨çš„æ­£å‘ä¼ æ’­
----------------

ä¸Šæ–‡æˆ‘ä»¬è®²åˆ°ï¼Œæ¯ä¸ªæ¨¡åž‹å‰å‘ä¼ é€’éƒ½ä¼šäº§ç”Ÿä¸‹ä¸€ä¸ª token çš„æ¦‚çŽ‡ï¼Œä½†è¿™å®žé™…ä¸Šæ˜¯ä¸€ä¸ªä¸å®Œæ•´çš„æè¿°ã€‚åœ¨æ–‡æœ¬ç”ŸæˆæœŸé—´ï¼Œå…¸åž‹çš„è¿­ä»£åŒ…æ‹¬æ¨¡åž‹æŽ¥æ”¶æœ€æ–°ç”Ÿæˆçš„ token ä½œä¸ºè¾“å…¥ï¼ŒåŠ ä¸Šæ‰€æœ‰å…¶ä»–å…ˆå‰è¾“å…¥çš„ç¼“å­˜å†…éƒ¨è®¡ç®—ï¼Œå†è¿”å›žä¸‹ä¸€ä¸ª token å¾—æ¦‚çŽ‡ã€‚ç¼“å­˜ç”¨äºŽé¿å…å†—ä½™è®¡ç®—ï¼Œä»Žè€Œå®žçŽ°æ›´å¿«çš„å‰å‘ä¼ é€’ï¼Œä½†å®ƒä¸æ˜¯å¼ºåˆ¶æ€§çš„ (å¹¶ä¸”å¯ä»¥è®¾ç½®éƒ¨åˆ†ä½¿ç”¨)ã€‚ç¦ç”¨ç¼“å­˜æ—¶ï¼Œè¾“å…¥åŒ…å«åˆ°ç›®å‰ä¸ºæ­¢ç”Ÿæˆçš„æ•´ä¸ª token åºåˆ—ï¼Œè¾“å‡ºåŒ…å« \_æ‰€æœ‰ä½ç½®\_çš„ä¸‹ä¸€ä¸ª token å¯¹åº”çš„æ¦‚çŽ‡åˆ†å¸ƒï¼å¦‚æžœè¾“å…¥ç”±å‰ N ä¸ª token ç»„æˆï¼Œåˆ™ç¬¬ N ä¸ªä½ç½®çš„è¾“å‡ºå¯¹åº”äºŽå…¶ä¸‹ä¸€ä¸ª token çš„æ¦‚çŽ‡åˆ†å¸ƒï¼Œå¹¶ä¸”è¯¥æ¦‚çŽ‡åˆ†å¸ƒå¿½ç•¥äº†åºåˆ—ä¸­çš„æ‰€æœ‰åŽç»­ tokenã€‚åœ¨è´ªå¿ƒè§£ç çš„ç‰¹æ®Šæƒ…å†µä¸‹ï¼Œå¦‚æžœä½ å°†ç”Ÿæˆçš„åºåˆ—ä½œä¸ºè¾“å…¥ä¼ é€’å¹¶å°† argmax è¿ç®—ç¬¦åº”ç”¨äºŽç”Ÿæˆçš„æ¦‚çŽ‡ï¼Œä½ å°†èŽ·å¾—ç”Ÿæˆçš„åºåˆ—ã€‚

    from transformers import AutoModelForCausalLM, AutoTokenizer
    
    tok = AutoTokenizer.from_pretrained("distilgpt2")
    model = AutoModelForCausalLM.from_pretrained("distilgpt2")
    
    inputs = tok(["The"], return_tensors="pt")
    generated = model.generate(**inputs, do_sample=False, max_new_tokens=10)
    forward_confirmation = model(generated).logits.argmax(-1)
    
    # We exclude the opposing tips from each sequence: the forward pass returns
    # the logits for the next token, so it is shifted by one position.
    print(generated[:-1].tolist() == forward_confirmation[1:].tolist()) # True
    

è¿™æ„å‘³ç€ä½ å¯ä»¥å°†æ¨¡åž‹å‰å‘ä¼ é€’ç”¨äºŽä¸åŒçš„ç›®çš„: é™¤äº†æä¾›ä¸€äº› token æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªæ ‡è®°å¤–ï¼Œä½ è¿˜å¯ä»¥å°†åºåˆ—ä¼ é€’ç»™æ¨¡åž‹å¹¶æ£€æŸ¥æ¨¡åž‹æ˜¯å¦ä¼šç”Ÿæˆç›¸åŒçš„åºåˆ— (æˆ–éƒ¨åˆ†ç›¸åŒåºåˆ—)ã€‚

![](https://devrel.andfun.cn/devrel/posts/2023-05-25-143914.png)

_(è¯·è®¿é—®é˜…è¯»åŽŸæ–‡æŸ¥çœ‹åŠ¨æ€æ¼”ç¤º)_

è®©æˆ‘ä»¬æƒ³è±¡ï¼Œä½ å¯ä»¥è®¿é—®ä¸€ä¸ªç¥žå¥‡çš„æ— å»¶è¿Ÿçš„é¢„æµ‹è¾…åŠ©æ¨¡åž‹ï¼Œè¯¥æ¨¡åž‹é’ˆå¯¹ä»»ä½•ç»™å®šè¾“å…¥ç”Ÿæˆä¸Žä½ çš„æ¨¡åž‹ç›¸åŒçš„åºåˆ—ã€‚é¡ºä¾¿è¯´ä¸€å¥ï¼Œè¿™ä¸ªæ¨¡åž‹ä¸èƒ½ç›´æŽ¥ç”¨ï¼Œåªèƒ½è¾…åŠ©ä½ çš„ç”Ÿæˆç¨‹åºã€‚ä½¿ç”¨ä¸Šè¿°å±žæ€§ï¼Œä½ å¯ä»¥ä½¿ç”¨æ­¤è¾…åŠ©æ¨¡åž‹èŽ·å–å€™é€‰è¾“å‡º tokenï¼Œç„¶åŽä½¿ç”¨ä½ çš„æ¨¡åž‹è¿›è¡Œå‰å‘ä¼ é€’ä»¥ç¡®è®¤å®ƒä»¬çš„æ­£ç¡®æ€§ã€‚åœ¨è¿™ä¸ªä¹Œæ‰˜é‚¦å¼çš„åœºæ™¯ä¸­ï¼Œæ–‡æœ¬ç”Ÿæˆçš„å»¶è¿Ÿå°†ä»Ž `O(n)` å‡å°‘åˆ° `O(1)`ï¼Œå…¶ä¸­ç”Ÿæˆçš„ token æ•°é‡ä¸º `n`ã€‚å¯¹äºŽéœ€è¦å¤šæ¬¡è¿­ä»£ç”Ÿæˆçš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬è°ˆè®ºçš„æ˜¯å…¶æ•°é‡çº§ã€‚

å‘çŽ°å®žè¿ˆå‡ºä¸€æ­¥ï¼Œæˆ‘ä»¬å‡è®¾è¾…åŠ©æ¨¡åž‹å¤±åŽ»äº†å®ƒçš„é¢„æµ‹å±žæ€§ã€‚æ ¹æ®ä½ çš„æ¨¡åž‹ï¼ŒçŽ°åœ¨å®ƒæ˜¯ä¸€ä¸ªæ— å»¶è¿Ÿæ¨¡åž‹ï¼Œä½†å®ƒä¼šå¼„é”™ä¸€äº›å€™é€‰ tokenã€‚ç”±äºŽä»»åŠ¡çš„è‡ªå›žå½’æ€§è´¨ï¼Œä¸€æ—¦è¾…åŠ©æ¨¡åž‹å¾—åˆ°ä¸€ä¸ªé”™è¯¯çš„ tokenï¼Œæ‰€æœ‰åŽç»­å€™é€‰ token éƒ½å¿…é¡»æ— æ•ˆã€‚ä½†æ˜¯ï¼Œä½ å¯ä»¥ä½¿ç”¨æ¨¡åž‹æ›´æ­£é”™è¯¯ token å¹¶åå¤é‡å¤æ­¤è¿‡ç¨‹åŽå†æ¬¡æŸ¥è¯¢è¾…åŠ©æ¨¡åž‹ã€‚å³ä½¿è¾…åŠ©æ¨¡åž‹å¤±è´¥äº†å‡ ä¸ª tokenï¼Œæ–‡æœ¬ç”Ÿæˆçš„å»¶è¿Ÿä¹Ÿä¼šæ¯”åŽŸå§‹å½¢å¼å°å¾—å¤šã€‚

æ˜¾ç„¶ï¼Œä¸–ç•Œä¸Šæ²¡æœ‰æ— å»¶è¿Ÿçš„è¾…åŠ©æ¨¡åž‹ã€‚ç„¶è€Œï¼Œæ‰¾åˆ°ä¸€ä¸ªè¿‘ä¼¼äºŽæ¨¡åž‹çš„æ–‡æœ¬ç”Ÿæˆè¾“å‡ºçš„å…¶å®ƒæ¨¡åž‹ç›¸å¯¹å®¹æ˜“ï¼Œä¾‹å¦‚ç»è¿‡ç±»ä¼¼è®­ç»ƒçš„ç›¸åŒæž¶æž„çš„è¾ƒå°ç‰ˆæœ¬æ¨¡åž‹é€šå¸¸ç¬¦åˆæ­¤éœ€æ±‚ã€‚å½“æ¨¡åž‹å¤§å°çš„å·®å¼‚å˜å¾—æ˜¾è‘—æ—¶ï¼Œä½¿ç”¨è¾ƒå°çš„æ¨¡åž‹ä½œä¸ºè¾…åŠ©æ¨¡åž‹çš„æˆæœ¬åœ¨è·³è¿‡å‡ ä¸ªå‰å‘ä¼ é€’åŽå°±æ˜¾å¾—æ— å…³ç´§è¦äº†ï¼çŽ°åœ¨ï¼Œä½ äº†è§£äº† \_ è¾…åŠ©ç”Ÿæˆ \_ çš„æ ¸å¿ƒã€‚

ä½¿ç”¨è¾…åŠ©æ¨¡åž‹çš„è´ªå¿ƒè§£ç 
-----------

è¾…åŠ©ç”Ÿæˆæ˜¯ä¸€ç§å¹³è¡¡è¡Œä¸ºã€‚ä½ å¸Œæœ›è¾…åŠ©æ¨¡åž‹å¿«é€Ÿç”Ÿæˆå€™é€‰åºåˆ—ï¼ŒåŒæ—¶å°½å¯èƒ½å‡†ç¡®ã€‚å¦‚æžœè¾…åŠ©æ¨¡åž‹çš„è´¨é‡å¾ˆå·®ï¼Œä½ å°†æ‰¿æ‹…ä½¿ç”¨è¾…åŠ©æ¨¡åž‹çš„æˆæœ¬ï¼Œè€Œæ”¶ç›Šå´å¾ˆå°‘ç”šè‡³æ²¡æœ‰ã€‚å¦ä¸€æ–¹é¢ï¼Œä¼˜åŒ–å€™é€‰åºåˆ—çš„è´¨é‡å¯èƒ½æ„å‘³ç€ä½¿ç”¨æ›´æ…¢çš„è¾…åŠ©æ¨¡åž‹ï¼Œä»Žè€Œå¯¼è‡´ç½‘ç»œå‡é€Ÿã€‚è™½ç„¶æˆ‘ä»¬æ— æ³•ä¸ºä½ è‡ªåŠ¨é€‰æ‹©è¾…åŠ©æ¨¡åž‹ï¼Œä½†æˆ‘ä»¬åŒ…å«äº†ä¸€ä¸ªé¢å¤–çš„è¦æ±‚å’Œä¸€ä¸ªå¯å‘å¼æ–¹æ³•ï¼Œä»¥ç¡®ä¿æ¨¡åž‹ä¸Žè¾…åŠ©æ¨¡åž‹ä¸€èµ·èŠ±è´¹çš„æ—¶é—´ä¿æŒåœ¨å¯æŽ§èŒƒå›´å†…ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬è¦æ±‚è¾…åŠ©æ¨¡åž‹å¿…é¡»å…·æœ‰ä¸Žä½ çš„æ¨¡åž‹å®Œå…¨ç›¸åŒçš„åˆ†è¯å™¨ã€‚å¦‚æžœæ²¡æœ‰æ­¤è¦æ±‚ï¼Œåˆ™å¿…é¡»æ·»åŠ æ˜‚è´µçš„ token è§£ç å’Œé‡æ–°ç¼–ç æ­¥éª¤ã€‚æ­¤å¤–ï¼Œè¿™äº›é¢å¤–çš„æ­¥éª¤å¿…é¡»åœ¨ CPU ä¸Šè¿›è¡Œï¼Œè¿™åè¿‡æ¥å¯èƒ½å¢žåŠ äº†è®¾å¤‡é—´æ•°æ®ä¼ è¾“ã€‚èƒ½å¤Ÿå¿«é€Ÿåœ°ä½¿ç”¨è¾…åŠ©æ¨¡åž‹å¯¹äºŽè¾…åŠ©ç”Ÿæˆçš„å¥½å¤„æ˜¯è‡³å…³é‡è¦çš„ã€‚

æœ€åŽï¼Œå¯å‘å¼ã€‚è‡³æ­¤ï¼Œä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°ç”µå½±ç›—æ¢¦ç©ºé—´å’Œè¾…åŠ©ç”Ÿæˆä¹‹é—´çš„ç›¸ä¼¼ä¹‹å¤„â€”â€”æ¯•ç«Ÿä½ æ˜¯åœ¨æ–‡æœ¬ç”Ÿæˆä¸­è¿è¡Œæ–‡æœ¬ç”Ÿæˆã€‚æ¯ä¸ªå€™é€‰ token æœ‰ä¸€ä¸ªè¾…åŠ©æ¨¡åž‹å‰å‘ä¼ æ’­ï¼Œæˆ‘ä»¬çŸ¥é“å‰å‘ä¼ æ’­æ˜¯æ˜‚è´µçš„ã€‚è™½ç„¶ä½ æ— æ³•æå‰çŸ¥é“è¾…åŠ©æ¨¡åž‹å°†èŽ·å¾—çš„ token æ•°é‡ï¼Œä½†ä½ å¯ä»¥è·Ÿè¸ªæ­¤ä¿¡æ¯å¹¶ä½¿ç”¨å®ƒæ¥é™åˆ¶å‘è¾…åŠ©æ¨¡åž‹è¯·æ±‚çš„å€™é€‰ token æ•°é‡â€”â€”è¾“å‡ºçš„æŸäº›éƒ¨åˆ†æ¯”å…¶å®ƒä¸€äº›éƒ¨åˆ†æ›´å®¹æ˜“è¢«é¢„è®¡ã€‚

æ€»ç»“ä¸€ä¸‹ï¼Œè¿™æ˜¯æˆ‘ä»¬æœ€åˆå®žçŽ°çš„è¾…åŠ©ç”Ÿæˆçš„å¾ªçŽ¯ ([ä»£ç ](https://github.com/huggingface/transformers/blob/849367ccf741d8c58aa88ccfe1d52d8636eaf2b7/src/transformers/generation/utils.py#L4064)):

1.  ä½¿ç”¨è´ªå¿ƒè§£ç ä¸Žè¾…åŠ©æ¨¡åž‹ç”Ÿæˆä¸€å®šæ•°é‡çš„`å€™é€‰ token`ã€‚å½“ç¬¬ä¸€æ¬¡è°ƒç”¨è¾…åŠ©ç”Ÿæˆæ—¶ï¼Œç”Ÿæˆçš„`å€™é€‰ token` çš„æ•°é‡è¢«åˆå§‹åŒ–ä¸º `5`ã€‚
2.  ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡åž‹ï¼Œå¯¹`å€™é€‰ token` è¿›è¡Œå‰å‘è®¡ç®—ï¼ŒèŽ·å¾—æ¯ä¸ª token å¯¹åº”çš„æ¦‚çŽ‡ã€‚
3.  ä½¿ç”¨ token é€‰æ‹©æ–¹æ³• (ä½¿ç”¨`.argmax()` è¿›è¡Œè´ªå¿ƒæœç´¢æˆ–ä½¿ç”¨ `.multinomial()` ç”¨äºŽé‡‡æ ·æ–¹æ³•) æ¥ä»Žæ¦‚çŽ‡ä¸­é€‰å– `next_tokens`ã€‚
4.  æ¯”è¾ƒæ­¥éª¤ 3 ä¸­é€‰æ‹©çš„ `next_tokens` å’Œ `å€™é€‰ token` ä¸­ç›¸åŒçš„ token æ•°é‡ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬éœ€è¦ä»Žå·¦åˆ°å³è¿›è¡Œæ¯”è¾ƒï¼Œ åœ¨ç¬¬ä¸€æ¬¡ä¸åŒ¹é…åŽï¼ŒåŽç»­æ‰€æœ‰ `å€™é€‰ token`éƒ½æ— æ•ˆã€‚5. ä½¿ç”¨æ­¥éª¤ 4 å¾—åˆ°çš„åŒ¹é…æ•°é‡å°†`å€™é€‰ token` åˆ†å‰²ã€‚ä¹Ÿå°±æ˜¯ï¼Œå°†è¾“å…¥ tokens åŠ ä¸ŠåˆšåˆšéªŒè¯å¾—åˆ°çš„æ­£ç¡®çš„ tokensã€‚
5.  è°ƒæ•´ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­ç”Ÿæˆçš„`å€™é€‰ token` çš„æ•°é‡ â€”â€” ä½¿ç”¨å¯å‘å¼æ–¹æ³•ï¼Œå¦‚æžœæ­¥éª¤ 3 ä¸­æ‰€æœ‰ token éƒ½åŒ¹é…ï¼Œåˆ™`å€™é€‰ token` çš„é•¿åº¦å¢žåŠ  `2`ï¼Œå¦åˆ™å‡å°‘ `1`ã€‚

![](https://devrel.andfun.cn/devrel/posts/2023-05-25-143917.png)

_(è¯·è®¿é—®é˜…è¯»åŽŸæ–‡æŸ¥çœ‹åŠ¨æ€æ¼”ç¤º)_

æˆ‘ä»¬åœ¨ ðŸ¤— Transformers ä¸­è®¾è®¡äº† APIï¼Œå› æ­¤ä½¿ç”¨è¯¥æ–¹æ³•å¯¹ä½ æ¥è¯´æ˜¯æ— ç—›çš„ã€‚ä½ éœ€è¦åšçš„å°±æ˜¯å°†è¾…åŠ©æ¨¡åž‹ä½œä¸º `assistant_model` å‚æ•°ä¼ å…¥ä»Žè€ŒèŽ·å¾—å»¶è¿Ÿæ”¶ç›Šï¼æˆ‘ä»¬æš‚æ—¶é™åˆ¶äº†è¾…åŠ©ç”Ÿæˆçš„æ‰¹é‡å¤§å°ä¸º `1`ã€‚

    from transformers import AutoModelForCausalLM, AutoTokenizer
    import torch
    
    prompt = "Alice and Bob"
    checkpoint = "EleutherAI/pythia-1.4b-deduped"
    assistant_checkpoint = "EleutherAI/pythia-160m-deduped"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    tokenizer = AutoTokenizer.from_pretrained(checkpoint)
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    
    model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)
    assistant_model = AutoModelForCausalLM.from_pretrained(assistant_checkpoint).to(device)
    outputs = model.generate(**inputs, assistant_model=assistant_model)
    print(tokenizer.batch_decode(outputs, skip_special_tokens=True))
    # ['Alice and Bob are sitting in a bar. Alice is drinking a beer and Bob is drinking a']
    

é¢å¤–çš„å†…éƒ¨å¤æ‚æ€§æ˜¯å¦å€¼å¾—ï¼Ÿè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹è´ªå¿ƒè§£ç æƒ…å†µä¸‹çš„å»¶è¿Ÿæ•° (é‡‡æ ·ç»“æžœåœ¨ä¸‹ä¸€èŠ‚)ã€‚è€ƒè™‘æ‰¹é‡å¤§å°ä¸º 1ï¼Œè¿™äº›ç»“æžœæ˜¯ç›´æŽ¥ä»Ž ðŸ¤— Transformers ä¸­æå–çš„ï¼Œæ²¡æœ‰ä»»ä½•é¢å¤–çš„ä¼˜åŒ–ï¼Œå› æ­¤ä½ åº”è¯¥èƒ½å¤Ÿåœ¨ä½ çš„è®¾ç½®ä¸­å¤çŽ°å®ƒä»¬ã€‚

![](https://devrel.andfun.cn/devrel/posts/2023-05-25-143918.png)  
Space ä½“éªŒåœ°å€: [https://hf.co/spaces/joaogante/assisted\_generation\_benchmarks](https://hf.co/spaces/joaogante/assisted_generation_benchmarks)

é€šè¿‡è§‚å¯Ÿæ”¶é›†åˆ°çš„æ•°æ®ï¼Œæˆ‘ä»¬å‘çŽ°è¾…åŠ©ç”Ÿæˆå¯ä»¥åœ¨ä¸åŒçš„è®¾ç½®ä¸­æ˜¾è‘—å‡å°‘å»¶è¿Ÿï¼Œä½†è¿™ä¸æ˜¯çµä¸¹å¦™è¯â€”â€”ä½ åº”è¯¥åœ¨åº”ç”¨ä¹‹å‰å¯¹å…¶è¿›è¡Œç³»ç»Ÿçš„è¯„ä¼°ä»¥æ¸…æ™°ä½¿ç”¨è¯¥æ–¹æ³•çš„ä»£ä»·ã€‚å¯¹äºŽè¾…åŠ©ç”Ÿæˆæ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®º:

1.  ðŸ¤ éœ€è¦è®¿é—®è‡³å°‘æ¯”ä½ çš„æ¨¡åž‹å°ä¸€ä¸ªæ•°é‡çº§çš„è¾…åŠ©æ¨¡åž‹ (å·®å¼‚è¶Šå¤§è¶Šå¥½) ;
2.  ðŸš€ åœ¨å­˜åœ¨ INT8 çš„æƒ…å†µä¸‹èŽ·å¾—é«˜è¾¾ 3 å€çš„åŠ é€Ÿï¼Œå¦åˆ™èƒ½å¤Ÿè¾¾åˆ° 2 å€çš„åŠ é€Ÿ;
3.  ðŸ¤¯ å¦‚æžœä½ æ­£åœ¨ä½¿ç”¨ä¸é€‚åˆä½ çš„æ¨¡åž‹çš„ GPU å¹¶ä¸”ä¾èµ–äºŽå†…å­˜å¸è½½çš„æ¨¡åž‹ï¼Œä½ å¯ä»¥çœ‹åˆ°é«˜è¾¾ 10 å€çš„åŠ é€Ÿ;
4.  ðŸ“„ åœ¨è¾“å…¥é©±åŠ¨ä»»åŠ¡ä¸­å¤§æ”¾å¼‚å½©ï¼Œä¾‹å¦‚è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æˆ–æ‘˜è¦ã€‚

è¾…åŠ©ç”Ÿæˆçš„é‡‡æ ·æ–¹æ³•
---------

è´ªå¿ƒè§£ç é€‚ç”¨äºŽä»¥è¾“å…¥ä¸ºåŸºç¡€çš„ä»»åŠ¡ (è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ã€ç¿»è¯‘ã€æ‘˜è¦â€¦â€¦) æˆ–äº‹å®žçŸ¥è¯†å¯»æ±‚ã€‚å¯¹äºŽéœ€è¦å¤§é‡åˆ›é€ åŠ›çš„å¼€æ”¾å¼ä»»åŠ¡ï¼Œä¾‹å¦‚ä½¿ç”¨è¯­è¨€æ¨¡åž‹ä½œä¸ºèŠå¤©æœºå™¨äººçš„å¤§å¤šæ•°ä»»åŠ¡ï¼Œåº”è¯¥æ”¹ç”¨é‡‡æ ·æ–¹æ³•ã€‚è™½ç„¶è¾…åŠ©ç”Ÿæˆæ–¹æ³•æ˜¯ä¸ºè´ªå¿ƒè§£ç è€Œè®¾è®¡çš„ï¼Œä½†è¿™å¹¶ä¸æ„å‘³ç€ä½ ä¸èƒ½ä½¿ç”¨å¤šé¡¹å¼é‡‡æ ·è¿›è¡Œè¾…åŠ©ç”Ÿæˆï¼

ä»Ž `next token` çš„æ¦‚çŽ‡åˆ†å¸ƒä¸­æŠ½å–æ ·æœ¬å°†å¯¼è‡´æˆ‘ä»¬çš„åŸºäºŽè´ªå¿ƒçš„è¾…åŠ©ç”Ÿäº§æ›´é¢‘ç¹åœ°å¤±è´¥ï¼Œä»Žè€Œé™ä½Žå…¶å»¶è¿Ÿä¼˜åŠ¿ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é‡‡æ ·ä¸­çš„æ¸©åº¦ç³»æ•°æ¥æŽ§åˆ¶ä¸‹ä¸€ä¸ªæ ‡è®°çš„æ¦‚çŽ‡åˆ†å¸ƒæœ‰å¤šå°–é”ã€‚åœ¨ä¸€ç§æžç«¯æƒ…å†µä¸‹ï¼Œå½“æ¸©åº¦æŽ¥è¿‘ 0 æ—¶ï¼Œé‡‡æ ·å°†è¿‘ä¼¼äºŽè´ªå¿ƒè§£ç ï¼Œæœ‰åˆ©äºŽæœ€æœ‰å¯èƒ½çš„ tokenã€‚åœ¨å¦ä¸€ä¸ªæžç«¯ï¼Œå½“æ¸©åº¦è®¾ç½®ä¸ºè¿œå¤§äºŽ 1 çš„å€¼æ—¶ï¼Œé‡‡æ ·å°†æ˜¯æ··ä¹±çš„ï¼Œä»Žå‡åŒ€åˆ†å¸ƒä¸­æŠ½å–ã€‚å› æ­¤ï¼Œä½Žæ¸©å¯¹ä½ çš„è¾…åŠ©æ¨¡åž‹æ›´æœ‰åˆ©ï¼Œèƒ½å¤Ÿä¿ç•™è¾…åŠ©ç”Ÿæˆçš„å¤§éƒ¨åˆ†å»¶è¿Ÿä¼˜åŠ¿ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

![](https://devrel.andfun.cn/devrel/posts/2023-05-25-143919.png)

ä¸å¦¨äº²çœ¼çœ‹ä¸€çœ‹ï¼Œæ„Ÿå—ä¸€ä¸‹è¾…åŠ©ç”Ÿæˆçš„é­…åŠ›ï¼Ÿ

![](https://devrel.andfun.cn/devrel/posts/2023-05-25-143920.png)

Space ä½“éªŒåœ°å€: [https://hf.co/spaces/joaogante/assisted\_generation\_demo](https://hf.co/spaces/joaogante/assisted_generation_demo)

æœªæ¥å‘å±•æ–¹å‘
------

è¾…åŠ©ç”Ÿæˆè¡¨æ˜Žå½“å‰æ–‡æœ¬ç”Ÿæˆç­–ç•¥å·²ç»åˆ°äº†å¯ä¼˜åŒ–çš„é˜¶æ®µã€‚æˆ‘ä»¬æ„è¯†åˆ°å®ƒç›®å‰çš„éš¾ç‚¹ä¸åœ¨äºŽè®¡ç®—é‡çš„é—®é¢˜ï¼Œå› æ­¤å¯ä»¥åº”ç”¨ç®€å•çš„å¯å‘å¼æ–¹æ³•æ¥å……åˆ†åˆ©ç”¨å¯ç”¨çš„å†…å­˜å¸¦å®½ï¼Œç¼“è§£ç“¶é¢ˆã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–è¾…åŠ©æ¨¡åž‹å°†ä½¿æˆ‘ä»¬èŽ·å¾—æ›´å¤§çš„å»¶è¿Ÿé™ä½Žâ€”â€”ä¾‹å¦‚ï¼Œå¦‚æžœæˆ‘ä»¬è¯·æ±‚è¾…åŠ©æ¨¡åž‹ç”Ÿæˆå¤šä¸ªè¿žç»­å€™é€‰ tokenï¼Œæˆ‘ä»¬å¯èƒ½èƒ½å¤Ÿè·³è¿‡æ›´å¤šçš„å‰å‘ä¼ é€’ã€‚è‡ªç„¶åœ°ï¼Œä½¿ç”¨é«˜è´¨é‡çš„å°æ¨¡åž‹ä½œä¸ºè¾…åŠ©æ¨¡åž‹å¯¹äºŽå®žçŽ°å’Œæ‰©å¤§æ”¶ç›Šè‡³å…³é‡è¦ã€‚

è¯¥æ–¹æ³•æœ€åˆåœ¨æˆ‘ä»¬çš„ ðŸ¤— Transformers åº“ä¸‹å‘å¸ƒï¼Œç”¨äºŽ `.generate()` å‡½æ•°ï¼Œæˆ‘ä»¬é¢„æœŸå°†å…¶çº³å…¥æ•´ä¸ª Hugging Face å®‡å®™ã€‚å®ƒçš„å®žçŽ°ä¹Ÿæ˜¯å®Œå…¨å¼€æºçš„ã€‚å› æ­¤ï¼Œå¦‚æžœä½ æ­£åœ¨è¿›è¡Œæ–‡æœ¬ç”Ÿæˆè€Œæ²¡æœ‰ä½¿ç”¨æˆ‘ä»¬çš„å·¥å…·ï¼Œä½ å¯ä»¥éšæ—¶å°†å…¶ä½œä¸ºå‚è€ƒã€‚

æœ€åŽï¼Œè¾…åŠ©ç”Ÿæˆé‡æ–°æå‡ºäº†æ–‡æœ¬ç”Ÿæˆä¸­çš„ä¸€ä¸ªå…³é”®é—®é¢˜: æ¨¡åž‹ä¸­æ‰€æœ‰æ–° token éƒ½æ˜¯ç»™å®šæ¨¡åž‹ä»¥è‡ªå›žå½’æ–¹å¼è®¡ç®—çš„ç»“æžœï¼ŒåŒè´¨åœ°å‰å‘ä¼ é€’æ¯ä¸€ä¸ª tokenã€‚è¿™ç¯‡åšæ–‡æå‡ºäº†è¿™æ ·çš„æƒ³æ³•: ç”Ÿæˆçš„å¤§éƒ¨åˆ†åºåˆ—ä¹Ÿå¯ä»¥ç”±å°å°ºå¯¸çš„æ¨¡åž‹åŒæ ·ç”Ÿæˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦æ–°çš„æ¨¡åž‹æž¶æž„å’Œè§£ç æ–¹æ³•â€”â€”æˆ‘ä»¬å¾ˆé«˜å…´çœ‹åˆ°æœªæ¥ä¼šå¸¦æ¥ä»€ä¹ˆï¼

ç›¸å…³å·¥ä½œ
----

åœ¨è¿™ç¯‡åšæ–‡æœ€åˆå‘å¸ƒåŽï¼Œæˆ‘æ³¨æ„åˆ°å…¶ä»–ä½œå“ä¹ŸæŽ¢ç´¢äº†ç›¸åŒçš„æ ¸å¿ƒåŽŸåˆ™ (ä½¿ç”¨å‰å‘ä¼ é€’æ¥éªŒè¯æ›´é•¿çš„è¿žç»­æ€§)ã€‚ç‰¹åˆ«åœ°ï¼Œè¯·çœ‹ä»¥ä¸‹ä½œå“:

*   [åˆ†å—å¹¶è¡Œè§£ç ](https://proceedings.neurips.cc/paper/2018/file/c4127b9194fe8562c64dc0f5bf2c93bc-Paper.pdf), æ¥è‡ª Google Brain
*   [æŽ¨æµ‹æ€§é‡‡æ ·](https://arxiv.org/abs/2302.01318), æ¥è‡ª DeepMind

Citation
--------

    @misc {gante2023assisted,
    	author = { {Joao Gante} },
    	title = { Assisted Generation: a new direction toward low-latency text generation },
    	year = 2023,
    	url = { https://huggingface.co/blog/assisted-generation },
    	doi = { 10.57967/hf/0638 },
    	publisher = { Hugging Face Blog }
    }
    

è‡´è°¢
--

æˆ‘è¦æ„Ÿè°¢ Sylvain Guggerã€Nicolas Patry å’Œ Lewis Tunstall åˆ†äº«äº†è®¸å¤šå®è´µçš„å»ºè®®æ¥æ”¹è¿›è¿™ç¯‡åšæ–‡ã€‚æœ€åŽï¼Œæ„Ÿè°¢ Chunte Lee è®¾è®¡äº†ç²¾ç¾Žçš„å°é¢ï¼Œä½ å¯ä»¥åœ¨æˆ‘ä»¬çš„ç½‘é¡µä¸Šçœ‹åˆ°ã€‚

* * *

> åŽŸæ–‡é“¾æŽ¥: [https://huggingface.co/blog/assisted-generation](https://huggingface.co/blog/assisted-generation)
> 
> ä½œè€…: Joao Gante
> 
> è¯‘è€…: gxy-gxy
> 
> æŽ’ç‰ˆ/å®¡æ ¡: zhongdongy (é˜¿ä¸œ)