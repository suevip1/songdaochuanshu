---
layout: post
title: "论文解读（CBL）《CNN-Based Broad Learning for Cross-Domain Emotion Classification》"
date: "2023-08-18T00:55:12.914Z"
---
论文解读（CBL）《CNN-Based Broad Learning for Cross-Domain Emotion Classification》
===========================================================================

Note：\[ wechat：Y466551 | 付费咨询，非诚勿扰 \]

论文信息
====

> 论文标题：CNN-Based Broad Learning for Cross-Domain Emotion Classification  
> 论文作者：Rong Zeng, Hongzhan Liu , Sancheng Peng , Lihong Cao, Aimin Yang, Chengqing Zong,Guodong Zhou  
> 论文来源：2023 aRxiv  
> 论文地址：download   
> 论文代码：download  
> 视屏讲解：click

1 介绍 
=====

　　出发点：许多研究者关注的是传统的跨域情感分类，即粗粒度情绪分类。然而，跨领域的情绪分类问题却很少被涉及到。

　　摘要：在本文中，提出了一种基于卷积神经网络（CNN）的广泛学习方法，通过结合 CNN 和广泛学习的强度来进行跨域情感分类。首先利用 CNN 同时提取领域不变和领域特定特征，通过广泛学习来训练两个更有效的分类器。然后，为了利用这两个分类器，设计了一个共同训练模型来为它们进行提升。

　　贡献：

*   *   提出了一种结合深度学习和广泛学习的模型，即基于卷积神经网络（CNN）的广泛学习（CBL）；
    *   开发了四个真实世界的数据集，涉及四个不同领域；
    *   结果表明，该方法比基线方法能更有效地提高情绪分类的性能；

2 方法
====

模型框架：

　　![](https://img2023.cnblogs.com/blog/1664108/202308/1664108-20230817173009208-1175438830.png)

2.1 Maximum mean discrepancy
----------------------------

　　MMD 公式：

　　　　$\\operatorname{MMD}\\left(X\_{s}, X\_{t}\\right)=\\left\\|\\frac{1}{N\_{s}} \\sum\_{i=1}^{N\_{s}} \\phi\\left(x\_{s}^{i}\\right)-\\frac{1}{N\_{t}} \\sum\_{i=1}^{N\_{t}} \\phi\\left(x\_{t}^{i}\\right)\\right\\|\_{\\mathcal{H}}^{2}  \\quad\\quad(1)$

2.2 Feature extraction
----------------------

　　本小节，为了同时提取 DIF（域不变特征） 和 DSF （域特定特征），先使用两个不同的映射器将数据映射到一个域不变的空间和一个域特定的空间中。

　　首先使用 BERT 来生成 $X\_s$ 和 $X\_{tl}$ 的词向量，其描述如下：

　　　　$\\begin{array}{l}\\boldsymbol{W}\_{i n v}^{s}=\\operatorname{BERT}\_{i n v}\\left(X\_{s} ; \\theta\_{i n v}^{\\mathrm{BERT}}\\right) \\in \\mathbf{R}^{\\left(N\_{s} l\\right) \\times 768} \\\\\\boldsymbol{W}\_{i n v}^{t l}=\\operatorname{BERT}\_{i n v}\\left(X\_{t l} ; \\theta\_{i n v}^{\\mathrm{BERT}}\\right) \\in \\mathbf{R}^{\\left(N\_{t l} l\\right) \\times 768}  \\\\\\boldsymbol{W}\_{s p e c}^{s}=\\operatorname{BERT}\_{s p e c}\\left(X\_{s} ; \\theta\_{\\text {spec }}^{\\mathrm{BERT}}\\right) \\in \\mathbf{R}^{\\left(N\_{s} l\\right) \\times 768}  \\\\\\boldsymbol{W}\_{s p e c}^{t l}=\\operatorname{BERT}\_{s p e c}\\left(X\_{t l} ; \\boldsymbol{\\theta}\_{\\text {spec }}^{\\mathrm{BERT}}\\right) \\in \\mathbf{R}^{\\left(N\_{t l} l\\right) \\times 768}\\end{array} \\quad\\quad(2)$

　　基于此，使用 CNN 和 最大池化 ，提取 n-gram feature 和 salient feature，可以描述如下：

　　　　$\\begin{array}{l}\\boldsymbol{F}\_{i n v}^{s}=\\mathrm{CNN}\_{i n v}\\left(\\boldsymbol{W}\_{i n v}^{s} ; \\theta\_{i n v}^{\\mathrm{CNN}}\\right) \\in \\mathbf{R}^{N\_{s} \\times q}  \\\\\\boldsymbol{F}\_{i n v}^{t l}=\\mathrm{CNN}\_{i n v}\\left(\\boldsymbol{W}\_{i n v}^{t l} ; \\theta\_{i n v}^{\\mathrm{CNN}}\\right) \\in \\mathbf{R}^{N\_{t l} \\times q}  \\\\\\boldsymbol{F}\_{s p e c}^{s}=\\mathrm{CNN}\_{s p e c}\\left(\\boldsymbol{W}\_{s p e c}^{s} ; \\boldsymbol{\\theta}\_{\\text {spec }}^{\\mathrm{CNN}}\\right) \\in \\mathbf{R}^{N\_{s} \\times q}  \\\\\\boldsymbol{F}\_{\\text {spec }}^{t l}=\\mathrm{CNN}\_{\\text {spec }}\\left(\\boldsymbol{W}\_{\\text {spec }}^{t l} ; \\boldsymbol{\\theta}\_{\\text {spec }}^{\\mathrm{CNN}}\\right) \\in \\mathbf{R}^{N\_{t l} \\times q}\\end{array} \\quad\\quad(3)$

　　对于 DIF，希望它能够编码源域和目标域共享的特性：

　　　　$L\_{s i m}=\\operatorname{MMD}\\left(\\boldsymbol{F}\_{i n v}^{s}, \\boldsymbol{F}\_{i n v}^{t l}\\right) \\quad\\quad(4)$

　　对于 DSF，希望它只从目标域中提取特征，这些特性通常应该出现在目标域中，而很少出现在源域中：

　　　　$L\_{d i f f}=-\\operatorname{MMD}\\left(\\boldsymbol{F}\_{\\text {spec }}^{s}, \\boldsymbol{F}\_{\\text {spec }}^{t l}\\right) \\quad\\quad(5)$

2.3 BL-Based classifier
-----------------------

　　为增强节点语义特征，设计了基于 DIF 的域不变分类器（DIC）和基于 DSF 的域特定分类器（DSC）两种分类器。

　　对于 DIC，第 $i$ 组增强节点可以表示如下：

　　　　$\\begin{array}{l}\\boldsymbol{E}\_{i n v}^{i} & =\\varphi\\left(\\theta\_{i n v}^{i}\\left\[\\boldsymbol{F}\_{i n v}^{s}, \\boldsymbol{F}\_{i n v}^{t l}\\right\]+\\boldsymbol{\\beta}\_{i n v}^{i}\\right) \\\\i & =1,2, \\ldots, n\_{i n v}\\end{array}  \\quad\\quad(6)$

　　增强的节点特征：$\\boldsymbol{E}\_{i n v} \\triangleq\\left\[\\boldsymbol{E}\_{i n v}^{1}, \\boldsymbol{E}\_{i n v}^{2}, \\ldots, \\boldsymbol{E}\_{i n v}^{n\_{i n v}}\\right\]$ 。

　　因此，DIC 的输出可以表示如下：

　　　　$\\hat{\\boldsymbol{Y}}\_{i n v}=\\left\[\\boldsymbol{F}\_{i n v}^{s}, \\boldsymbol{F}\_{i n v}^{t l}, \\boldsymbol{E}\_{i n v}\\right\] \\boldsymbol{\\theta}\_{i n v}^{\\mathrm{BL}}=\\boldsymbol{A}\_{i n v} \\theta\_{i n v}^{\\mathrm{BL}}   \\quad\\quad(7)$

　　由于 DSC 只需要对目标域数据进行分类，因此我们对 $\\boldsymbol{F}\_{\\text {spec }}^{\\text {tl }}$ 到增强节点的 $n\_{\\text {spec }}$ 组进行了非线性映射。因此，第 $j$ 组增强节点可以表示如下：

　　　　$\\begin{array}{l}\\boldsymbol{E}\_{s p e c}^{j} & =\\varphi\\left(\\boldsymbol{\\theta}\_{s p e c}^{j} \\boldsymbol{F}\_{s p e c}^{t l}+\\boldsymbol{\\beta}\_{s p e c}^{j}\\right) \\\\j & =1,2, \\ldots, n\_{s p e c}\\end{array}  \\quad\\quad(8)$

　　增强的节点特征：$\\boldsymbol{E}\_{\\text {spec }} \\triangleq\\left\[\\boldsymbol{E}\_{\\text {spec }}^{1}, \\boldsymbol{E}\_{\\text {spec }}^{2}, \\ldots, \\boldsymbol{E}\_{\\text {spec }}^{n\_{\\text {spec }}}\\right\]$

　　因此，DSC的输出可以表示如下：

　　　　$\\hat{\\boldsymbol{Y}}\_{s p e c}=\\left\[\\boldsymbol{F}\_{s p e c}^{t l}, \\boldsymbol{E}\_{s p e c}\\right\] \\boldsymbol{\\theta}\_{s p e c}^{\\mathrm{BL}}=\\boldsymbol{A}\_{s p e c} \\theta\_{s p e c}^{\\mathrm{BL}}   \\quad\\quad(9)$

2.4 Co-training
---------------

　　至于DIF，训练的目的是尽量减少以下损失：

　　　　$L\_{i n v}=L\_{s i m}\\left(\\theta\_{i n v}^{\\mathrm{BERT}}, \\boldsymbol{\\theta}\_{i n v}^{\\mathrm{CNN}}\\right)+\\alpha L\_{c}\\left(\\boldsymbol{\\theta}\_{i n v}^{\\mathrm{BERT}}, \\theta\_{i n v}^{\\mathrm{CNN}}\\right)   \\quad\\quad(10)$

　　　　$\\begin{aligned}L\_{c}= & \\frac{1}{N\_{s}+N\_{t l}} \\sum\_{i=1}^{N\_{s}}-y\_{s}^{i} \\ln P\\left(y\_{s}^{i} \\mid \\boldsymbol{F}\_{i n v}^{s i}\\right)+  \\frac{1}{N\_{s}+N\_{t l}} \\sum\_{j=1}^{N\_{t l}}-y\_{t l}^{j} \\ln P\\left(y\_{t l}^{j} \\mid \\boldsymbol{F}\_{i n v}^{t l j}\\right)\\end{aligned}  \\quad\\quad(11)$

　　在到DSF时，训练的目的是尽量减少下面的损失:

　　　　$L\_{\\text {spec }}=L\_{\\text {diff }}\\left(\\boldsymbol{\\theta}\_{\\text {spec }}^{\\mathrm{BERT}}, \\theta\_{\\text {spec }}^{\\mathrm{CNN}}\\right)+\\gamma L\_{t}\\left(\\theta\_{\\text {spec }}^{\\mathrm{BERT}}, \\boldsymbol{\\theta}\_{\\text {spec }}^{\\mathrm{CNN}}\\right)  \\quad\\quad(12)$

　　　　$L\_{t}=\\frac{1}{N\_{t l}} \\sum\_{i=1}^{N\_{t l}}-\\boldsymbol{Y}\_{t l}^{i} \\log f c\\left(y\_{t l}^{i} \\mid \\boldsymbol{F}\_{s p e c}^{t l i}\\right)  \\quad\\quad(13)$

　　对于 DIC，我们需要求解一个合适的 $\\boldsymbol{\\theta}\_{i n v}^{\\mathrm{BERT}}$，使 $\\boldsymbol{Y}\_{i n v}$ 和 $\\hat{\\boldsymbol{Y}}\_{i n v}$ 之间的差异尽可能小，其中 $\\boldsymbol{Y}\_{i n v}$ 表示标记源数据和标记目标数据的地面真实标签。因此，采用岭回归作为目标函数，其表示如下：

　　　　$\\underset{\\boldsymbol{\\theta}\_{i n v}^{\\mathrm{BL}}}{\\operatorname{argmin}}\\left(\\left\\|\\boldsymbol{Y}\_{i n v}-\\hat{\\boldsymbol{Y}}\_{i n v}\\right\\|\_{2}^{2}+\\lambda\_{1}\\left\\|\\boldsymbol{\\theta}\_{i n v}^{\\mathrm{BL}}\\right\\|\_{2}^{2}\\right) \\quad\\quad(14)$

　　对于 DSC，同样，目标函数表示如下：

　　　　$\\underset{\\boldsymbol{\\theta}\_{\\text {spec }}^{\\mathrm{BL}}}{\\operatorname{argmin}}\\left(\\left\\|\\boldsymbol{Y}\_{\\text {spec }}-\\hat{\\boldsymbol{Y}}\_{\\text {spec }}\\right\\|\_{2}^{2}+\\lambda\_{2}\\left\\|\\boldsymbol{\\theta}\_{\\text {spec }}^{\\mathrm{BL}}\\right\\|\_{2}^{2}\\right) \\quad\\quad(15)$

　　$\\boldsymbol{Y}\_{\\text {spec }}$ 表示已标记的目标数据的地面真实标签。

　　因此，采用岭回归作为目标函数，得到最优解 $\\theta\_{i n v}^{\\mathrm{BL}}$，表示如下：

　　　　$\\boldsymbol{\\theta}\_{i n v}^{\\mathrm{BL}}=\\left(\\lambda\_{1} \\boldsymbol{I}+\\boldsymbol{A}\_{i n v} \\boldsymbol{A}\_{i n v}^{\\mathrm{T}}\\right)^{-1} \\boldsymbol{A}\_{i n v}^{\\mathrm{T}} \\boldsymbol{Y}\_{i n v}   \\quad\\quad(16)$

　　其中，$I$ 表示单位矩阵。

　　同样，得到最优解 $\\theta\_{\\text {spec }}^{\\mathrm{BL}}$ 规范，表示如下：

　　　　$\\theta\_{\\text {spec }}^{\\mathrm{BL}}=\\left(\\lambda\_{2} \\boldsymbol{I}+\\boldsymbol{A}\_{\\text {spec }} \\boldsymbol{A}\_{\\text {spec }}^{\\mathrm{T}}\\right)^{-1} \\boldsymbol{A}\_{\\text {spec }}^{\\mathrm{T}} \\boldsymbol{Y}\_{\\text {spec }}  \\quad\\quad(17)$

2.5 完整算法
--------

　　　　![](https://img2023.cnblogs.com/blog/1664108/202307/1664108-20230729153348235-831672651.png)

3 实验结果
======

数据集

　　![](https://img2023.cnblogs.com/blog/1664108/202308/1664108-20230817190821048-79754755.png)

情感分类

　　![](https://img2023.cnblogs.com/blog/1664108/202308/1664108-20230817190751173-1052020250.png)

因上求缘，果上努力~~~~ 作者：[Wechat~Y466551](https://www.cnblogs.com/BlairGrowing/)，转载请注明原文链接：[https://www.cnblogs.com/BlairGrowing/p/17589407.html](https://www.cnblogs.com/BlairGrowing/p/17589407.html)