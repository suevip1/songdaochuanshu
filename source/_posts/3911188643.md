---
layout: post
title: "yolotv5和resnet152模型预测"
date: "2023-06-01T01:42:06.779Z"
---
yolotv5和resnet152模型预测
=====================

我已经训练完成了yolov5检测和resnet152分类的模型，下面开始对一张图片进行检测分类。

首先用yolo算法对猫和狗进行检测，然后将检测到的目标进行裁剪，然后用resnet152对裁剪的图片进行分类。

首先我有以下这些训练好的模型

![](https://img2023.cnblogs.com/blog/2042155/202305/2042155-20230531204440351-1286479500.png)

 猫狗检测的，猫的分类，狗的分类

我的预测文件my\_detect.py

import os
import sys
from pathlib import Path

from tools\_detect import draw\_box\_and\_save\_img, dataLoad, predict\_classify, detect\_img\_2\_classify\_img, get\_time\_uuid

FILE \= Path(\_\_file\_\_).resolve()
ROOT \= FILE.parents\[0\]  # YOLOv5 root directory
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # add ROOT to PATH
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative

from models.common import DetectMultiBackend
from utils.general import (non\_max\_suppression)
from utils.plots import save\_one\_box

import config as cfg

conf\_thres \= cfg.conf\_thres
iou\_thres \= cfg.iou\_thres

detect\_size \= cfg.detect\_img\_size
classify\_size \= cfg.classify\_img\_size

def detect\_img(img, device, detect\_weights='', detect\_class=\[\], save\_dir=''):
    # 选择计算设备
    # device = select\_device(device)
    # 加载数据
    imgsz = (detect\_size, detect\_size)
    im0s, im \= dataLoad(img, imgsz, device)
    # print(im0)
    # print(im)
    # 加载模型
    model = DetectMultiBackend(detect\_weights, device=device)
    stride, names, pt \= model.stride, model.names, model.pt
    # print((1, 3, \*imgsz))
    model.warmup(imgsz=(1, 3, \*imgsz))  # warmup
    pred \= model(im, augment=False, visualize=False)
    # print(pred)
    pred = non\_max\_suppression(pred, conf\_thres, iou\_thres, None, False, max\_det=1000)
    # print(pred)
    im0 = im0s.copy()
    # 画框，保存图片
    # ret\_bytes= None
    ret\_bytes = draw\_box\_and\_save\_img(pred, names, detect\_class, save\_dir, im0, im)
    ret\_li \= list()
    # print(pred)
    im0\_arc = int(im0.shape\[0\]) \* int(im0.shape\[1\])
    count \= 1
    for det in reversed(pred\[0\]):
        # print(det)
        # print(det)
        # 目标太小跳过
        xyxy\_arc = (int(det\[2\]) - int(det\[0\])) \* (int(det\[3\]) - int(det\[1\]))
        # print(xyxy\_arc)
        if xyxy\_arc / im0\_arc < 0.01:
            continue
        # 裁剪图片
        xyxy = det\[:4\]
        im\_crop \= save\_one\_box(xyxy, im0, file=Path('im.jpg'), gain=1.1, pad=10, square=False, BGR=False, save=False)
        # 将裁剪的图片转为分类的大小及tensor类型
        im\_crop = detect\_img\_2\_classify\_img(im\_crop, classify\_size, device)

        d \= dict()
        # print(det)
        c = int(det\[-1\])
        label \= detect\_class\[c\]
        # 开始做具体分类
        if label == detect\_class\[0\]:
            classify\_predict \= predict\_classify(cfg.cat\_weight, im\_crop, device)
            classify\_label \= cfg.cat\_class\[int(classify\_predict)\]
        else:
            classify\_predict \= predict\_classify(cfg.dog\_weight, im\_crop, device)
            classify\_label \= cfg.dog\_class\[int(classify\_predict)\]
        # print(classify\_label)
        d\['details'\] = classify\_label
        conf \= round(float(det\[-2\]), 2)
        d\['label'\] = label+str(count)
        d\['conf'\] = conf
        ret\_li.append(d)
        count += 1

    return ret\_li, ret\_bytes

def start\_predict(img, save\_dir=''):
    weights \= cfg.detect\_weight
    detect\_class \= cfg.detect\_class
    device \= cfg.device
    ret\_li, ret\_bytes \= detect\_img(img, device, weights, detect\_class, save\_dir)
    # print(ret\_li)
    return ret\_li, ret\_bytes

if \_\_name\_\_ == '\_\_main\_\_':
    name \= get\_time\_uuid()
    save\_dir \= f'./save/{name}.jpg'
    # path = r'./test\_img/hashiqi20230312\_00010.jpg'
    path = r'./test\_img/hashiqi20230312\_00116.jpg'
    # path = r'./test\_img/kejiquan20230312\_00046.jpg'
    f = open(path, 'rb')
    img \= f.read()
    f.close()
    # print(img)
    # print(type(img))
    img\_ret\_li, img\_bytes = start\_predict(img, save\_dir=save\_dir)
    print(img\_ret\_li)

我的tools\_detect.py文件

import datetime
import os
import random
import sys
import time
from pathlib import Path

import torch
from PIL import Image
from torch import nn

from utils.augmentations import letterbox

FILE \= Path(\_\_file\_\_).resolve()
ROOT \= FILE.parents\[0\]  # YOLOv5 root directory
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # add ROOT to PATH
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative

from utils.general import (cv2,
                           scale\_boxes, xyxy2xywh)
from utils.plots import Annotator, colors
import numpy as np

def bytes\_to\_ndarray(byte\_img):
    """
    图片二进制转numpy格式
    """
    image \= np.asarray(bytearray(byte\_img), dtype="uint8")
    image \= cv2.imdecode(image, cv2.IMREAD\_COLOR)
    return image

def ndarray\_to\_bytes(ndarray\_img):
    """
    图片numpy格式转二进制
    """
    ret, buf \= cv2.imencode(".jpg", ndarray\_img)
    img\_bin \= Image.fromarray(np.uint8(buf)).tobytes()
    # print(type(img\_bin))
    return img\_bin

def get\_time\_uuid():
    """
        :return: 20220525140635467912
        :PS ：并发较高时尾部随机数增加
    """
    uid \= str(datetime.datetime.fromtimestamp(time.time())).replace("\-", "").replace(" ", "").replace(":","").replace(".", "") + str(random.randint(100, 999))
    return uid

def dataLoad(img, img\_size, device, half=False):
    image \= bytes\_to\_ndarray(img)
    # print(image.shape)
    im = letterbox(image, img\_size)\[0\]  # padded resize
    im = im.transpose((2, 0, 1))\[::-1\]  # HWC to CHW, BGR to RGB
    im = np.ascontiguousarray(im)  # contiguous
    im \= torch.from\_numpy(im).to(device)
    im \= im.half() if half else im.float()  # uint8 to fp16/32
    im /= 255  # 0 - 255 to 0.0 - 1.0
    if len(im.shape) == 3:
        im \= im\[None\]  # expand for batch dim

    return image, im

def draw\_box\_and\_save\_img(pred, names, class\_names, save\_dir, im0, im):

    save\_path \= save\_dir
    fontpath \= "./simsun.ttc"
    for i, det in enumerate(pred):
        annotator \= Annotator(im0, line\_width=3, example=str(names), font=fontpath, pil=True)
        if len(det):
            det\[:, :4\] = scale\_boxes(im.shape\[2:\], det\[:, :4\], im0.shape).round()
            count \= 1
            im0\_arc \= int(im0.shape\[0\]) \* int(im0.shape\[1\])
            gn \= torch.tensor(im0.shape)\[\[1, 0, 1, 0\]\]
            base\_path \= os.path.split(save\_path)\[0\]
            file\_name \= os.path.split(save\_path)\[1\].split('.')\[0\]
            txt\_path \= os.path.join(base\_path, 'labels')
            if not os.path.exists(txt\_path):
                os.mkdir(txt\_path)
            txt\_path \= os.path.join(txt\_path, file\_name)
            for \*xyxy, conf, cls in reversed(det):
                # 目标太小跳过
                xyxy\_arc = (int(xyxy\[2\]) - int(xyxy\[0\])) \* (int(xyxy\[3\]) - int(xyxy\[1\]))
                # print(im0.shape, xyxy, xyxy\_arc, im0\_arc, xyxy\_arc / im0\_arc)
                if xyxy\_arc / im0\_arc < 0.01:
                    continue
                # print(im0.shape, xyxy)
                c = int(cls)  # integer class
                label = f"{class\_names\[c\]}{count} {round(float(conf), 2)}" #  .encode('utf-8')
                # print(xyxy)
                annotator.box\_label(xyxy, label, color=colors(c, True))

                im0 \= annotator.result()
                count += 1
                # print(im0)

                # print(type(im0))
                # im0 为 numpy.ndarray类型

                # Write to file
                # print('+++++++++++')
                xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                # print(xywh)
                line = (cls, \*xywh)  # label format
                with open(f'{txt\_path}.txt', 'a') as f:
                    f.write(('%g ' \* len(line)).rstrip() % line + '\\n')
    cv2.imwrite(save\_path, im0)

    ret\_bytes \= ndarray\_to\_bytes(im0)
    return ret\_bytes

def predict\_classify(model\_path, img, device):
    # im = torch.nn.functional.interpolate(img, (160, 160), mode='bilinear', align\_corners=True)
    # print(device)
    if torch.cuda.is\_available():
        model \= torch.load(model\_path)
    else:
        model \= torch.load(model\_path, map\_location='cpu')
    # print(help(model))
    model.to(device)
    model.eval()
    predicts \= model(img)
    \_, preds \= torch.max(predicts, 1)
    pred \= torch.squeeze(preds)
    # print(pred)
    return pred

def detect\_img\_2\_classify\_img(img, classify\_size, device):
    im\_crop1 \= img.copy()
    im\_crop1 \= np.float32(im\_crop1)
    image \= cv2.resize(im\_crop1, (classify\_size, classify\_size))
    image \= image.transpose((2, 0, 1))
    im \= torch.from\_numpy(image).unsqueeze(0)
    im\_crop \= im.to(device)
    return im\_crop

我的config.py文件

import torch
import os

base\_path \= r'.\\weights'

detect\_weight \= os.path.join(base\_path, r'cat\_dog\_detect/best.pt')
detect\_class \= \['猫', '狗'\]

cat\_weight \= os.path.join(base\_path, r'cat\_predict/best.pt')
cat\_class \= \['东方短毛猫', '亚洲豹猫', '加菲猫', '安哥拉猫', '布偶猫', '德文卷毛猫', '折耳猫', '无毛猫', '暹罗猫', '森林猫', '橘猫', '奶牛猫', '狞猫', '狮子猫', '狸花猫', '玳瑁猫', '白猫', '蓝猫', '蓝白猫', '薮猫', '金渐层猫', '阿比西尼亚猫', '黑猫'\]

dog\_weight \= os.path.join(base\_path, r'dog\_predict/best.pt')
dog\_class \= \['中华田园犬', '博美犬', '吉娃娃', '哈士奇', '喜乐蒂', '巴哥犬', '德牧', '拉布拉多犬', '杜宾犬', '松狮犬', '柯基犬', '柴犬', '比格犬', '比熊', '法国斗牛犬', '秋田犬', '约克夏', '罗威纳犬', '腊肠犬', '萨摩耶', '西高地白梗犬', '贵宾犬', '边境牧羊犬', '金毛犬', '阿拉斯加犬', '雪纳瑞', '马尔济斯犬'\]

# device = 0
# device = torch.device('cuda' if torch.cuda.is\_available() else 'cpu')
device = torch.device('cpu')
conf\_thres \= 0.5
iou\_thres \= 0.45

detect\_img\_size \= 416
classify\_img\_size \= 160

整体文件结构

![](https://img2023.cnblogs.com/blog/2042155/202305/2042155-20230531204954289-1868204674.png)

 其中models和utils文件夹都是yolov5源码的文件

运行my\_detect.py的结果

![](https://img2023.cnblogs.com/blog/2042155/202305/2042155-20230531205121455-2008913939.png)