---
layout: post
title: "在阿里云和腾讯云的轻量应用服务器上搭建Hadoop集群"
date: "2023-09-20T00:57:16.575Z"
---
在阿里云和腾讯云的轻量应用服务器上搭建Hadoop集群
===========================

引入
==

本文在两台2核2g的云服务器上搭建了Hadoop集群，两台云服务器分别是阿里云（hjm）和腾讯云（gyt），集群部署规划如下：

hjm

gyt

HDFS

NameNode\\SecondaryNameNode\\DataNode

DataNode

YARN

ResourceManager\\NodeManager

NodeManager

经实验，目前可以正常实现文件上传下载，但跑mapreduce程序还出现服务器资源不够的情况

搭建过程
====

新增用户
----

    useradd hujinming
    passwd hujinming
    

配置用户sudo权限
----------

    vim /etc/sudoers
    

在

    ## Allow root to run any commands anywhere
    root ALL=(ALL) ALL
    ## Allows people in group wheel to run all commands
    %wheel ALL=(ALL) ALL
    

下面新增一行

    hujinming ALL=(ALL) NOPASSWD:ALL
    

创建目录并更改权限
---------

在/opt 目录下创建 module、software 文件夹

    mkdir /opt/module
    mkdir /opt/software
    

切换到root用户下，修改 module、software 文件夹的所有者和所属组均为hujinming用户

    chown hujinming:hujinming /opt/module
    chown hujinming:hujinming /opt/software
    

查看 module、software 文件夹的所有者和所属组

    ll
    

安装JDK
-----

*   用xftp工具将jdk导入到opt目录下面的software文件夹下面
*   解压jdk到opt/module目录下

    tar -zxvf jdk-8u212-linux.x64.tar.gz -C /opt/module/
    

*   配置jdk环境变量
    
    *   新建/etc/profile.d/my\_env.sh 文件
    
        sudo vim /etc/profile.d/my_env.sh
        
    
    *   添加如下内容
    
        #JAVA_HOME
        export JAVA_HOME=/opt/module/jdk1.8.0_212
        export PATH=$PATH:$JAVA_HOME/bin
        
    
    *   保存后退出，source 一下/etc/profile 文件，让新的环境变量 PATH 生效
    
        source /etc/profile
        
    
    *   测试jdk是否安装成功
    
        java -version
        
    

安装hadoop
--------

*   xftp传输
    
*   解压安装到/opt/module下面
    
*   将hadoop添加到环境变量
    
    *   获取hadoop安装路径
        
            pwd
            
        
    *   打开/etc/profile.d/my\_env.sh 文件
        
            sudo vim /etc/profile.d/my_env.sh
            
        
    *   在 my\_env.sh 文件末尾添加如下内容：
        
            #HADOOP_HOME
            export HADOOP_HOME=/opt/module/hadoop-3.1.3
            export PATH=$PATH:$HADOOP_HOME/bin
            export PATH=$PATH:$HADOOP_HOME/sbin
            
        
    *   保存退出，让修改后的文件生效
        
    *   测试是否安装成功
        

服务器IP映射
-------

*   修改主机名

    vim /etc/hostname
    

分别把两台服务器的名字改成hjm和gyt，这里以gyt举例，直接在hostname文件上输入

    gyt
    

*   改映射文件

    vim /etc/hosts
    

在linux中键入ifconfig命令可以查看内网ip。在两台服务器中，填写自己的私网，访问别人的填写公网，这里以gyt为例，gyt的公网IP是175.178.236.48，内网IP是10.0.12.1。这里要注意一点，阿里云在hosts文件中已经将本地IP映射成了一串英文，把这行信息删掉再进行上面的操作

    47.115.207.108 hjm
    10.0.12.1 gyt
    

*   在客户端电脑（默认windows）配置映射
    
    因为在客户端电脑进行hadoop的操作时，两台机子会产生通信，他们通信时发送的网络请求url是gyt或者hjm，这在客户端电脑是无法识别的，所以要将gyt和hjm都映射为他们的公网IP
    
    *   windows + R
        
    *   输入drivers，回车
        
    *   进入etc文件
        
    *   编辑hosts文件（都是公网IP）
        
            175.178.236.48 gyt
            47.115.207.108 hjm
            
        

ssh免密登录
-------

分别要配置4种免密登录：

*   hjm -> gyt
*   gyt -> hjm
*   hjm -> hjm
*   gyt -> gyt

注意切换对应用户操作。先cd到~/.ssh，生成公钥和私钥

    ssh-keygen -t rsa
    

这里以gyt -> hjm或hjm -> hjm为例：

    ssh-copy-id hjm
    

修改配置文件
------

cd到$HADOOP\_HOME/etc/hadoop目录

### core-site.xml

    <configuration>
     <!-- 指定 NameNode 的地址 -->
     <property>
     <name>fs.defaultFS</name>
     <value>hdfs://hjm:8020</value>
     </property>
     <!-- 指定 hadoop 数据的存储目录 -->
     <property>
     <name>hadoop.tmp.dir</name>
     <value>/opt/module/hadoop-3.1.3/data</value>
     </property>
     <!-- 配置 HDFS 网页登录使用的静态用户为 root -->
     <property>
     <name>hadoop.http.staticuser.user</name>
     <value>hujinming</value>
     </property>
    </configuration>
    

### hdfs-site.xml

    <configuration>
    <!-- nn web 端访问地址-->
    <property>
     <name>dfs.namenode.http-address</name>
     <value>hjm:9870</value>
     </property>
    <!-- 2nn web 端访问地址-->
     <property>
     <name>dfs.namenode.secondary.http-address</name>
     <value>hjm:9868</value>
     </property>
    </configuration>
    

### yarn-site.xml

    <configuration>
     <!-- 指定 MR 走 shuffle -->
     <property>
     <name>yarn.nodemanager.aux-services</name>
     <value>mapreduce_shuffle</value>
     </property>
     <!-- 指定 ResourceManager 的地址-->
     <property>
     <name>yarn.resourcemanager.hostname</name>
     <value>hjm</value>
     </property>
     <!-- 环境变量的继承 -->
     <property>
     <name>yarn.nodemanager.env-whitelist</name>
     
    <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CO
    NF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP
    RED_HOME</value>
     </property>
    </configuration>
    

### mapred-site.xml

    <configuration>
    <!-- 指定 MapReduce 程序运行在 Yarn 上 -->
     <property>
     <name>mapreduce.framework.name</name>
     <value>yarn</value>
     </property>
    </configuration>
    

### workers

    hjm
    gyt
    

去服务器上启动对应端口
-----------

*   用各自的服务器对双方暴露所有的端口
*   同时，对公网暴露9864、9866、9870、9868端口

问题与解决
=====

1.  ./sbin/start-dfs.sh 开启NameNode 和 DataNode 守护进程报错：
    
        Starting namenodes on [hjm]
        ERROR: Attempting to operate on hdfs namenode as root
        ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
        Starting datanodes
        ERROR: Attempting to operate on hdfs datanode as root
        ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.
        Starting secondary namenodes [hjm]
        ERROR: Attempting to operate on hdfs secondarynamenode as root
        ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.
        
    
    解决方法：
    
    在hjm上的start-dfs.sh和stop-dfs.sh上增加如下几行：
    
        HDFS_DATANODE_USER=hujinming
        HADOOP_SECURE_SECURE_USER=hdfs
        HDFS_NAMENODE_USER=hujinming
        HDFS_SECONDARYNAMENODE_USER=hujinming
        
    
    在hjm上的start-yarn.sh和stop-yarn.sh上增加如下几行：
    
        YARN_RESOURCEMANAGER_USER=hujinming
        HADOOP_SECURE_DN_USER=yarn
        YARN_NODEMANAGER_USER=hujinming
        
    
2.  报错hjm: ERROR: Cannot set priority of namenode process 23214，没有启动NameNode和SecondaryNameNode
    

​ 解决方法：

​ 在两台服务器的/etc/hosts中，填写自己的私网，访问别人的填写公网

3.  找不到NameNode和SecondaryNameNode

​ 解决方法：

​ 把所有节点logs和data删掉，重新格式化namenode，在hjm机子上，执行下面命令：

    hdfs namenode -format
    

4.  客户端（windows）识别不了hjm和gyt

​ 解决方法：改windows下面的主机名映射

5.  配置WebUI可跨域？

​ 解决方法：在两台服务器的core-site.xml加入下面代码

            <!--web console cors settings-->
            <property>
                <name>hadoop.http.filter.initializers</name>
                <value>org.apache.hadoop.security.HttpCrossOriginFilterInitializer</value>
            </property>
            <property>
                <name>hadoop.http.cross-origin.enabled</name>
                <value>true</value>
            </property>
            <property>
                <name>hadoop.http.cross-origin.allowed-origins</name>
                <value>*</value>
            </property>
            <property>
                <name>hadoop.http.cross-origin.allowed-methods</name>
                <value>*</value>
            </property>
            <property>
                <name>hadoop.http.cross-origin.allowed-headers</name>
                <value>X-Requested-With,Content-Type,Accept,Origin</value>
            </property>
            <property>
                <name>hadoop.http.cross-origin.max-age</name>
                <value>1800</value>
            </property>
    

6.  没有足够的副本数量？

​ 解决方法：还得看DataNode的数量。因为目前只有2台设备，最多也就2个副本，HDFS默认是3个副本，只有节点数的增加到10台时，副本数才能达到10。详细请看https://www.yii666.com/article/664023.html

7.  hadoop脚本启动时，错误： ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain？

​ 解决方法：在master主机的slaves文件中删除localhost即可。详细请看https://blog.csdn.net/Mr\_ZNC/article/details/80700652

8.  HDFS的webui界面上传下载文件，出现卡死情况？

​ 解决方法：暴露服务器所有端口给对方