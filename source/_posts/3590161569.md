---
layout: post
title: "HiAI Foundation助力端侧音视频AI能力，高性能低功耗释放云侧成本"
date: "2023-09-13T00:57:57.815Z"
---
HiAI Foundation助力端侧音视频AI能力，高性能低功耗释放云侧成本
=======================================

过去三年是端侧AI高速发展的几年，华为在2020年预言了端侧AI的发展潮流，2021年通过提供端云协同的方式使我们的HiAI Foundation应用性更进一个台阶，2022年提供视频超分端到端的解决方案，在2023HDC大会上，[HiAI Foundation](https://developer.huawei.com/consumer/cn/doc/development/hiai-Guides/introduction-0000001051486804?ha_source=hms1)基于硬件能力的开放，提供更多场景高效能的解决方案。

华为HiAI Foundation提供了高性能AI算子和丰富的AI特性的接口，App直接对应HiAI Foundation的DDK。今年完整支持了HarmonyOS NEXT，开发者无需修改任何代码，只需按照HarmonyOS NEXT的要求重新编译即可运行。同时，在开发者联盟网站有HarmonyOS NEXT指导文档，在Gitee上也开源了对应的Demo，降低大家的集成成本。

今年，华为在原有的基础上，拓展了更多端侧AI场景解决方案。

![](https://oscimg.oschina.net/oscnet/up-8cf3b81d56fcba7b62912d8bec00d7cd02d.png)

华为HiAI Foundation是基于硬件创新架构的能力开放，构建了一个高性能的NPU、CPU、GPU算子，同时提供整网融合、AIPP硬化预处理、算子搜索工具、异构计算等多元的基础能力，在硬件创新架构和多元竞争基础的能力上，提供生态开放机制，在生态开放机制上提供对用户开放的接口DDK工具链、模型轻量化、算子库动态升级、开源等等机制。

![](https://oscimg.oschina.net/oscnet/up-ae80049d9ebcf5a8acb6dc900e5585d948c.png)

华为HiAI Foundation主要由以下几个部分构成，首先是HiAI Foundation DDK推理加速平台，它主要完成与上层推理框架的接入，使开发者可以屏蔽底层硬件，能够更加聚焦于模型效果的优化。第二部分是异构计算HCL平台，它主要是使能各个硬件，比如NPU、CPU、GPU。第三部分是提供对应的工具链，包括模型转换工具链、异构调优工具链。同时我们也提供了统一的API，通过一次开发可以做到赋能多形态的设备硬件上运行，并且华为HiAI Foundation可以与HarmonyOS实时融合。

![](https://oscimg.oschina.net/oscnet/up-c665d61d32c5e19dd41ba036f68723a17d9.png)

下面以典型AI场景为例，从部署的角度来探索一下华为HiAI Foundation是如何完成这些挑战，并最终实现这些场景的落地。

**视觉类加速方案人像分割**

我们知道人像分割通常用于视频中的背景替换、长短视频的弹幕穿人玩法等。华为HiAI Foundation通过人像分割，通过AIPP硬化预处理指令、模型量化，使得人像分割达到性能和功耗的业务要求。从视频解码和开通预览流到AIPP推理和GPU渲染，有多个过程参与，华为HiAI Foundation不仅要进行推理，还要完成上下游的深度协同。

![](https://oscimg.oschina.net/oscnet/up-2acf4ab8d4f663dbad92123abbf4a4172db.gif)

![](https://oscimg.oschina.net/oscnet/up-6cb503cbdbb7e08754338f1a40453be7a7a.gif)

视频流和开放预览帧到模型，以人像分割为例，人像分割要求的输入是RGB格式，并且输入要求是固定的尺寸，视频解码帧和预览流出来的数据，要求支持图像预处理的指令，并且把它硬化到NPU里面，所以人像分割提供了包括图片缩放resize、图片旋转rotation、色域转换color space convert的能力。基于华为实验室测试结果，实现性能提升20%，模型大小缩小75%，精度损失1%以内，性能提升19%。

第二部分是模型在NPU上的高效算子推理，推理结束之后将结果送到GPU上做渲染。在传统方案中，NPU和GPU通常是操作两块不同的内存，华为HiAI Foundation提供了零拷贝的接口，将NPU和GPU在同一块内存上操作，并且在格式上保持严格一致，通过多IP协同+AIPP实现高效人像分割计算。

![](https://oscimg.oschina.net/oscnet/up-de3b0e39b978f74aab7d3183925a3c25dc7.png)

在端侧部署过程中提供了模型可视化+Profiling工具，通过模型可视化了解HiAI Foundation结构，通过Profiling知道IP的分布，包括算子在NPU和GPU的推理时间，综合起来通过可视化工具和Profiling工具设计出系统友好的结构，设计性能最佳的模型。

![](https://oscimg.oschina.net/oscnet/up-2d4158379af7b5423d9e72dcf425c318a09.png)

通过Profiling工具了解到模型算子的性能不够友好，然后把它反馈到HiAI Foundation，我们在支持好这些算子之后，通过端云协同的方式快速推送到用户手中，使用户能够尽快上线业务。本次华为在端云协同助力性能优化快速升级方面做了全面的升级，开发者无SDK就可以集成，相比原来繁琐的集成要求，可以做到无感集成。

![](https://oscimg.oschina.net/oscnet/up-60804c359b4ad7a868e7ad3af0203e1eca1.png)

**语音类的加速方案语音识别**

端侧部署语音识别实时出字、响应快，在端侧执行可以保证用户的隐私，此外华为能做到在NPU上执行，稳定性高，并且可以降低云侧的资源部署成本。在语音识别这一块，HiAI Foundation支持的是端到端的Transformer模型，全部在云端推理。基于华为实验室测试结果，模型量化模型大小缩小74%，精度损失1%以内。

模型如图所示，支持Transformer模型，开发者可以根据自身的业务，根据性能和泛化性来进行定制，也可以实现高效的算子融合。

![](https://oscimg.oschina.net/oscnet/up-212f8a5909731cb7dc3c8eeac8a41266592.png)

将原来需要频繁和内存交互的指令融合成一个大的算子，通过对这些关键结构进行算子融合，总共带来了60%的功耗收益，将左边很多小算子组成的结构融合成一个大算子，避免这些小算子频繁和内存进行交互，从而提升了运算效率。

![](https://oscimg.oschina.net/oscnet/up-891943cd2442888867520ad261890077682.png)

在端侧部署的过程中，存储空间也是开发者们关注的问题，希望用更小的存储空间来实现更多更强的能力，所以华为提供量化工具链，通过量化工具链可以量化出更小巧、更灵活的模型。以人像分割和语音识别为例，基于华为实验室测试结果，它们的存储大小能够相比32位浮点减少70%以上，精度WER指标相比32浮点小于1%，相应的功率也有一定的提升。

![](https://oscimg.oschina.net/oscnet/up-7234ec6f9f289b0c5576500822679bc1ddf.png)

在端侧AI部署中会涉及到硬件、软件和AI算法，所以华为通过开源的方式来加速业务，通过更多方式灵活部署。目前开放了推理源码的开源，通过开源可以做到和App、第三方深度学习框架对接，同时可以基于自身的需求做灵活的定制裁剪，做到开发灵活，通过这些开源平台能和开发者沟通更便捷。通过这些开源，开发者可以快速下载、编译，即可在华为手机上用NPU做推理，更高效集成业务。

未来，华为会探索Transformer模型更加泛化、更高能效的场景化解决方案，同时在端云协同上也会探索更多更高性能场景的能力支持，也会通过ModelZoo提供更多场景NPU友好的模型结构，用户可以设计更加NPU友好的模型结构。

**了解更多详情>>**

访问[HMS Core 联盟官网](http://developer.huawei.com/consumer/cn/hms?ha_source=hms1)

获取[HMS Core 开发指导文档](http://developer.huawei.com/consumer/cn/doc/development?ha_source=hms1)

**关注我们，第一时间了解 HMS Core 最新技术资讯~**